{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aabd674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "books = [\n",
    "    \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%201%20-%20The%20Philosopher's%20Stone.txt\",\n",
    "    \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%202%20-%20The%20Chamber%20of%20Secrets.txt\",\n",
    "    \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%203%20-%20The%20Prisoner%20of%20Azkaban.txt\",\n",
    "    \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%204%20-%20The%20Goblet%20of%20Fire.txt\",\n",
    "    \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%205%20-%20The%20Order%20of%20the%20Phoenix.txt\",\n",
    "    \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%206%20-%20The%20Half%20Blood%20Prince.txt\",\n",
    "    \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%207%20-%20The%20Deathly%20Hallows.txt\"\n",
    "]\n",
    "\n",
    "if not os.path.exists('books'):\n",
    "    os.makedirs('books')\n",
    "\n",
    "for i, book in enumerate(books):\n",
    "    with open(f'books/book_{i}.txt', 'w+') as book_file:\n",
    "        book_file.write(requests.get(book).text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b172a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import glob\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "words_counter = Counter()\n",
    "paragraphs = []\n",
    "\n",
    "for i, book in enumerate(sorted(glob.glob('books/*.txt'))):\n",
    "    with open(book, 'r') as book_file:\n",
    "        text = book_file.read().lower()\n",
    "        text = re.sub(r'^[Pp]age.*?$', '', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = text.replace('â€™', \"'\")\n",
    "        text = text.replace(\"'s\", '')\n",
    "        \n",
    "        # remove all non-alphanumeric characters\n",
    "        text = re.sub(r\"[^a-zA-Z0-9\\s]\", '', text)\n",
    "        \n",
    "        words_counter.update(text.split(' '))\n",
    "        \n",
    "\n",
    "words = {word: [{}, word, count] for word, count in words_counter.items() if len(word) > 1 and count > 10}\n",
    "words_copy = words.copy()\n",
    "for word in words.keys():\n",
    "    if word.endswith('s'):\n",
    "        del words_copy[word]\n",
    "\n",
    "words = words_copy\n",
    "\n",
    "with open('hp-words.json', 'w+') as words_file:\n",
    "    words_file.write(json.dumps(words))\n",
    "\n",
    "\n",
    "paragraphs = []\n",
    "for i, book in enumerate(glob.glob('books/*.txt')):\n",
    "    with open(book, 'r') as book_file:\n",
    "        text = book_file.read().lower()\n",
    "        text = re.sub(r'^[Pp]age.*?$', '', text, flags=re.MULTILINE)\n",
    "        paragraphs.extend(re.split(r'\\n\\s*\\n', text))\n",
    "paragraphs = [p for p in paragraphs if len(p) > 50]\n",
    "paragraphs = [p.replace('\\n', '') for p in paragraphs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45929d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "655ce13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d79763459742b38119403fadcf8992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_embeddings = model.encode(paragraphs, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ab57c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a011b743",
   "metadata": {},
   "outputs": [
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/ubuntu/models/bart-fine-tuned-msmarco-with-context-1.65'. Use `repo_type` argument if needed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\n\u001b[1;32m      7\u001b[0m transformers\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mset_verbosity_error()\n\u001b[0;32m----> 9\u001b[0m bart_tokenizer \u001b[39m=\u001b[39m BartTokenizerFast\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m'\u001b[39;49m\u001b[39m/home/ubuntu/models/bart-fine-tuned-msmarco-with-context-1.65\u001b[39;49m\u001b[39m'\u001b[39;49m, repo_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlocal\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     10\u001b[0m bart_model \u001b[39m=\u001b[39m BartForConditionalGeneration\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39m/home/ubuntu/models/bart-fine-tuned-msmarco-with-context-1.65\u001b[39m\u001b[39m'\u001b[39m, repo_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlocal\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     11\u001b[0m \u001b[39m# bart_tokenizer = T5Tokenizer.from_pretrained('t5-small')\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m# bart_model = T5ForConditionalGeneration.from_pretrained('~/models/t5-autocomplete').cpu()\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# from optimum.bettertransformer import BetterTransformer\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# bart_model = BetterTransformer.transform(bart_model, keep_original_model=False)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1727\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1724\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtokenizer_file\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m vocab_files:\n\u001b[1;32m   1725\u001b[0m     \u001b[39m# Try to get the tokenizer config to see if there are versioned tokenizer files.\u001b[39;00m\n\u001b[1;32m   1726\u001b[0m     fast_tokenizer_file \u001b[39m=\u001b[39m FULL_TOKENIZER_FILE\n\u001b[0;32m-> 1727\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m   1728\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   1729\u001b[0m         TOKENIZER_CONFIG_FILE,\n\u001b[1;32m   1730\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1731\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   1732\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   1733\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1734\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1735\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1736\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1737\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   1738\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   1739\u001b[0m         _raise_exceptions_for_missing_entries\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1740\u001b[0m         _raise_exceptions_for_connection_errors\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1741\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m   1742\u001b[0m     )\n\u001b[1;32m   1743\u001b[0m     commit_hash \u001b[39m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   1744\u001b[0m     \u001b[39mif\u001b[39;00m resolved_config_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py:409\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    406\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    407\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    410\u001b[0m         path_or_repo_id,\n\u001b[1;32m    411\u001b[0m         filename,\n\u001b[1;32m    412\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    413\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    414\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    415\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    416\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    417\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    418\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    419\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    420\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    421\u001b[0m     )\n\u001b[1;32m    423\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m    424\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    425\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    426\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlisted on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mfor\u001b[39;00m arg_name, arg_value \u001b[39min\u001b[39;00m chain(\n\u001b[1;32m    110\u001b[0m     \u001b[39mzip\u001b[39m(signature\u001b[39m.\u001b[39mparameters, args),  \u001b[39m# Args values\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     kwargs\u001b[39m.\u001b[39mitems(),  \u001b[39m# Kwargs values\u001b[39;00m\n\u001b[1;32m    112\u001b[0m ):\n\u001b[1;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrepo_id\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 114\u001b[0m         validate_repo_id(arg_value)\n\u001b[1;32m    116\u001b[0m     \u001b[39melif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m arg_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m         has_token \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:166\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    162\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRepo id must be a string, not \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(repo_id)\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m repo_id\u001b[39m.\u001b[39mcount(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    167\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must be in the form \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrepo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnamespace/repo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Use `repo_type` argument if needed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m     )\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m REPO_ID_REGEX\u001b[39m.\u001b[39mmatch(repo_id):\n\u001b[1;32m    172\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    173\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must use alphanumeric chars or \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m forbidden, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m cannot start or end the name, max length is 96:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     )\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/ubuntu/models/bart-fine-tuned-msmarco-with-context-1.65'. Use `repo_type` argument if needed."
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizerFast, BartForConditionalGeneration\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers.models.bart.modeling_bart import shift_tokens_right\n",
    "import torch\n",
    "import datetime\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "bart_tokenizer = BartTokenizerFast.from_pretrained('/home/ubuntu/models/bart-fine-tuned-msmarco-with-context-1.65', repo_type='local')\n",
    "bart_model = BartForConditionalGeneration.from_pretrained('/home/ubuntu/models/bart-fine-tuned-msmarco-with-context-1.65', repo_type='local').cuda()\n",
    "# bart_tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "# bart_model = T5ForConditionalGeneration.from_pretrained('~/models/t5-autocomplete').cpu()\n",
    "# from optimum.bettertransformer import BetterTransformer\n",
    "# bart_model = BetterTransformer.transform(bart_model, keep_original_model=False)\n",
    "\n",
    "all_tokens = list(bart_tokenizer.get_vocab().values())\n",
    "\n",
    "def do_autocomplete(query):\n",
    "    t = datetime.datetime.now()\n",
    "    if query == '':\n",
    "        return []\n",
    "    encoded_query = model.encode([query])\n",
    "    k=20\n",
    "    knn = util.semantic_search(encoded_query, corpus_embeddings, top_k=k)[0]\n",
    "    knn = [paragraphs[hit['corpus_id']] for hit in knn]\n",
    "    # prompt = f'{query}<mask>#{\";\".join(knn)}'\n",
    "    prompt = f'{query}<mask>#{\"; \".join(knn)}'\n",
    "\n",
    "    tokenized = \\\n",
    "        bart_tokenizer(prompt, return_tensors='pt', max_length=1024, truncation=True)\n",
    "    output = bart_model.generate(\n",
    "        input_ids=tokenized['input_ids'].cuda(),\n",
    "        attention_mask=tokenized['attention_mask'].cuda(),\n",
    "        early_stopping=True,\n",
    "        num_beams=1,\n",
    "        num_return_sequences=1,\n",
    "        length_penalty=4.0\n",
    "        )\n",
    "    results = [bart_tokenizer.decode(o, skip_special_tokens=True) for o in output]\n",
    "    return {'results': results, 'knn': knn, 'time': (datetime.datetime.now() - t).total_seconds()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d7ba6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'do_autocomplete' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mwhy did Dudley\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m suggestions \u001b[39m=\u001b[39m do_autocomplete(query)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mquery: \u001b[39m\u001b[39m'\u001b[39m, query)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39msuggestions: \u001b[39m\u001b[39m'\u001b[39m, suggestions)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'do_autocomplete' is not defined"
     ]
    }
   ],
   "source": [
    "query = 'why did Dudley'\n",
    "\n",
    "\n",
    "suggestions = do_autocomplete(query)\n",
    "print('query: ', query)\n",
    "print('suggestions: ', suggestions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b099d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = '''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>|\n",
    "    <meta charset='utf-8'>\n",
    "    <meta http-equiv='X-UA-Compatible' content='IE=edge'>\n",
    "    <title>Page Title</title>\n",
    "    <meta name='viewport' content='width=device-width, initial-scale=1'>\n",
    "    <script>\n",
    "        let timeout = null;\n",
    "        async function complete() {\n",
    "            document.getElementById('completion').innerHTML = '';\n",
    "            if (timeout !== null) {\n",
    "                clearTimeout(timeout);\n",
    "            }\n",
    "            timeout = setTimeout(async () => {\n",
    "                let query = document.getElementById('query').value;\n",
    "                if (query.length < 5) {\n",
    "                    return;\n",
    "                }\n",
    "                let result = await fetch('/autocomplete?query=' + encodeURIComponent(query));\n",
    "                let json = await result.json();\n",
    "                document.getElementById('completion').innerHTML = json.results.join('<br>') + '<br><br>' + json.knn.join('<br>') + '<br><br> time: ' + json.time;\n",
    "            }, 300);\n",
    "        }\n",
    "    </script>\n",
    "</head>\n",
    "<body>\n",
    "    <input type=\"text\" id=\"query\" onkeyup=\"complete()\" placeholder=\"Search...\" title=\"Type in a name\">\n",
    "    <p id=\"completion\"></p>\n",
    "</body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53a0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from fastapi.responses import HTMLResponse\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return HTMLResponse(index)\n",
    "\n",
    "@app.get('/autocomplete')\n",
    "async def autocomp(query: str):\n",
    "    return do_autocomplete(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9769ec9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [1281]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     147.235.213.96:3668 - \"GET /autocomplete?query=can%20hermione%20tim HTTP/1.1\" 200 OK\n",
      "INFO:     147.235.213.96:3680 - \"GET /autocomplete?query=can%20hermione%20time HTTP/1.1\" 200 OK\n",
      "INFO:     147.235.213.96:3680 - \"GET /autocomplete?query=can%20hermione%20 HTTP/1.1\" 200 OK\n",
      "INFO:     147.235.213.96:3680 - \"GET /autocomplete?query=how%20do%20 HTTP/1.1\" 200 OK\n",
      "INFO:     147.235.213.96:3680 - \"GET /autocomplete?query=how%20do%20you%20destroy HTTP/1.1\" 200 OK\n",
      "INFO:     147.235.213.96:3680 - \"GET /autocomplete?query=how%20do%20you%20destroy HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [1281]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import uvicorn\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = uvicorn.Config(app, host='0.0.0.0', port=3000)\n",
    "    server = uvicorn.Server(config)\n",
    "    await server.serve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bba170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
