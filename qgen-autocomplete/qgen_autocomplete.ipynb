{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "books = [\n",
    "    \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%201%20-%20The%20Philosopher's%20Stone.txt\",\n",
    "    # \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%202%20-%20The%20Chamber%20of%20Secrets.txt\",\n",
    "    # \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%203%20-%20The%20Prisoner%20of%20Azkaban.txt\",\n",
    "    # \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%204%20-%20The%20Goblet%20of%20Fire.txt\",\n",
    "    # \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%205%20-%20The%20Order%20of%20the%20Phoenix.txt\",\n",
    "    # \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%206%20-%20The%20Half%20Blood%20Prince.txt\",\n",
    "    # \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%207%20-%20The%20Deathly%20Hallows.txt\"\n",
    "]\n",
    "\n",
    "if not os.path.exists('books'):\n",
    "    os.makedirs('books')\n",
    "\n",
    "for i, book in enumerate(books):\n",
    "    with open(f'books/book_{i}.txt', 'w+') as book_file:\n",
    "        book_file.write(requests.get(book).text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "paragraphs = []\n",
    "\n",
    "for i, book in enumerate(books):\n",
    "    with open(f'books/book_{i}.txt', 'r') as book_file:\n",
    "        text = book_file.read()\n",
    "        text = re.sub(r'^[Pp]age.*?$', '', text, flags=re.MULTILINE)\n",
    "        paragraphs.extend(re.split(r'\\n\\s*\\n', text))\n",
    "        \n",
    "paragraphs = [p for p in paragraphs if len(p) > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "pargraphs = random.shuffle(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('BeIR/query-gen-msmarco-t5-large-v1')\n",
    "model = T5ForConditionalGeneration.from_pretrained('BeIR/query-gen-msmarco-t5-large-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_queries = []\n",
    "\n",
    "for paragraph in paragraphs[:30]:\n",
    "    input_ids = tokenizer.encode(paragraph, return_tensors='pt')\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=64,\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=3)\n",
    "\n",
    "    generated_queries.extend([tokenizer.decode(output, skip_special_tokens=True) for output in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "bi_encoder = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f3567462a849019b9ae76c47ccfc54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_queries = bi_encoder.encode(generated_queries, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who is the headmaster\n",
      "is it bad to stay up late with the headmaster\n",
      "who's that teacher talking to professor quirrell?\n",
      "who was the professor that looked up professor mcgonagall\n",
      "who's that teacher talking to professor quirrell\n"
     ]
    }
   ],
   "source": [
    "query = bi_encoder.encode(['who is the headmaster'])\n",
    "results = util.semantic_search(query, encoded_queries, top_k=5)\n",
    "for result in results[0]:\n",
    "    print(generated_queries[result['corpus_id']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
