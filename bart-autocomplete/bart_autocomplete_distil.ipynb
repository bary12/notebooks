{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "bart_tokenizer = BartTokenizerFast.from_pretrained('~/models/bart-fine-tuned-msmarco-with-context-1.65')\n",
    "bart_model = BartForConditionalGeneration.from_pretrained('~/models/bart-fine-tuned-msmarco-with-context-1.65')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartConfig\n",
    "\n",
    "config = BartConfig(\n",
    "    encoder_layers=3,\n",
    "    decoder_layers=3,\n",
    ")\n",
    "distilbart = BartForConditionalGeneration(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset('ms_marco', 'v2.1', split='train[:5000]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "bi_encoder = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(dataset)):\n",
    "    corpus.extend(dataset[i]['passages']['passage_text'])\n",
    "\n",
    "corpus_embeddings = bi_encoder.encode(corpus, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bart.modeling_bart import shift_tokens_right\n",
    "from sentence_transformers import util\n",
    "import random\n",
    "import torch\n",
    "random.seed(42)\n",
    "\n",
    "def random_mask(query):\n",
    "    words = query.split()\n",
    "    if len(query) < 3 or len(words) < 2:\n",
    "        return query\n",
    "    \n",
    "    mask_index = random.randint(len(words[0]), len(query) - 1)\n",
    "    return query[:mask_index]\n",
    "\n",
    "def convert_to_features6(batch):\n",
    "    random.shuffle(batch['passages'])\n",
    "    masked_queries = list(map(random_mask, batch['query']))\n",
    "\n",
    "    query_embeddings = bi_encoder.encode(masked_queries, convert_to_tensor=True)\n",
    "    masked_queries = [query + '<mask>' for query in masked_queries]\n",
    "    knn = util.semantic_search(query_embeddings, corpus_embeddings, top_k=10)\n",
    "    contexts = ['; '.join([corpus[e['corpus_id']] for e in embeddings]) for embeddings in knn]\n",
    "\n",
    "    inputs = [query + '# ' + context for context, query in zip(contexts, masked_queries)]\n",
    "\n",
    "    input_encodings = tokenizer.batch_encode_plus(inputs, padding='max_length', max_length=1024, truncation=True, return_tensors='pt')\n",
    "    label_encodings = tokenizer.batch_encode_plus(batch['query'], padding='max_length', max_length=1024, truncation=True, return_tensors='pt')\n",
    "    labels = label_encodings['input_ids']\n",
    "    # decoder_input_ids = shift_tokens_right(labels, model.config.pad_token_id)\n",
    "    labels[labels[:,:] == model.config.pad_token_id] = -100\n",
    "    \n",
    "    encodings = {\n",
    "        'input_ids': input_encodings['input_ids'],\n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        # 'decoder_input_ids': decoder_input_ids,\n",
    "        'labels': labels,\n",
    "        'masked_queries': masked_queries,\n",
    "    }\n",
    "\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>what is a lego</s> lego brick</s></s> of the most amazing bricks</s>']\n"
     ]
    }
   ],
   "source": [
    "from transformers.models.bart.modeling_bart import shift_tokens_right\n",
    "\n",
    "tokenized = bart_tokenizer(\"what is a <mask>#a lego brick is one of the most amazing bricks\", return_tensors=\"pt\")\n",
    "# decoder_input_ids = shift_tokens_right(tokenized['input_ids'], bart_tokenizer.pad_token_id, bart_tokenizer.eos_token_id)\n",
    "tokenized['input_ids'] = bart_model(**tokenized, decoder_input_ids=decoder_input_ids).logits.argmax(dim=-1)\n",
    "\n",
    "print(bart_tokenizer.batch_decode(tokenized['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['</s><s>what is a lego</s>']\n"
     ]
    }
   ],
   "source": [
    "print(bart_tokenizer.batch_decode(bart_model.generate(**tokenized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 50264, 2], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_tokenizer('<mask>')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
