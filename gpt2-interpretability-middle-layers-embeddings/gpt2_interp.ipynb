{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2-large')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-large').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer.batch_encode_plus(['Who is Barack Obama? The man who has been'], return_tensors='pt')\n",
    "output = model(\n",
    "    input_ids=tokenized['input_ids'].cuda(),\n",
    "    attention_mask=tokenized['attention_mask'].cuda(),\n",
    "    output_hidden_states=True,\n",
    "    output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  been -1\n",
      "1  replaced  been taken able seen replaced getting found considered made living\n",
      "2  effected  able seen taken getting been made living going found extremely\n",
      "3  rescued  able taken seen made rescued removed replaced treated documented exposed\n",
      "4  rescued  able seen taken removed rescued made exposed treated been going\n",
      "5  rescued  able seen taken made removed been rescued going documented considered\n",
      "6  rescued  able seen taken made been going removed documented rescued living\n",
      "7  rescued  able seen taken made been rescued removed born going studied\n",
      "8  rescued  able taken seen made been going described rescued attacked used\n",
      "9  seen  seen able taken made attacked talked used described called been\n",
      "10  seen  seen able made taken described talked called attacked used been\n",
      "11  seen  seen made able taken talked described used attacked called going\n",
      "12  rescued  made seen taken able talked described attacked called used successful\n",
      "13  historically  made seen taken able talked described attacked going historically called\n",
      "14  seen  seen taken able made talked described attacked viewed going criticized\n",
      "15  historically  talked seen made attacked taken going described historically so able\n",
      "16  historically  described historically talked going seen attacked made taken accused able\n",
      "17  historically  historically talked consistently described going so able repeatedly accused made\n",
      "18  historically  so going talked consistently described a historically accused able asked\n",
      "19  historically  so going talked described consistently able a repeatedly accused historically\n",
      "20  historically  so described able going a given accused called talked historically\n",
      "21  accused  described so a accused able given called talked repeatedly going\n",
      "22  accused  able accused described so given a born awarded called going\n",
      "23  described  described able a president accused given born called so in\n",
      "24  president  president able described a elected President accused Obama in called\n",
      "25  president  president able a President elected described the in so called\n",
      "26  president  president the President a able described Obama elected called so\n",
      "27  president  president the President called elected a described in able Obama\n",
      "28  president  president the a elected described in President called able dubbed\n",
      "29  president  president the a elected described President in called able an\n",
      "30  president  president the in a described elected President called an accused\n",
      "31  president  president the in a elected President described on called an\n",
      "32  president  in the president a called elected on described President an\n",
      "33  president  in the president a on called described President elected an\n",
      "34  president  in the a president on an called President described at\n",
      "35  president  in the a president on an called at, our\n",
      "36  president  in the a on an president at, called our\n"
     ]
    }
   ],
   "source": [
    "tokenized = tokenizer('president', return_tensors='pt')['input_ids'].cuda()\n",
    "president = model.transformer.wte(tokenized)[0]\n",
    "import torch\n",
    "for i, layer in enumerate(output.hidden_states):\n",
    "    diff = -1\n",
    "    if i > 0:\n",
    "        # diff = torch.cosine_similarity(layer[:,-1,:], output.hidden_states[i - 1][:,-1,:], dim=1).item()\n",
    "        diff = torch.cosine_similarity(layer[:,-1,:], model.transformer.wte.weight, dim=1)\n",
    "        diff = tokenizer.decode(torch.topk(diff, 10).indices)\n",
    "        # diff = torch.norm(layer[:,-1,:], dim=1).item()\n",
    "    layer = model.lm_head(layer)\n",
    "    print(i, tokenizer.decode(layer.argmax(dim=-1)[0][-1]), diff)\n",
    "\n",
    "    # layer = output.attentions[i]\n",
    "    # if i > 0:\n",
    "    #     # diff = torch.cosine_similarity(layer[:,-1,:], output.hidden_states[i - 1][:,-1,:], dim=1).item()\n",
    "    #     diff = torch.cosine_similarity(layer[:,-1,:], model.transformer.wte.weight, dim=1)\n",
    "    #     diff = tokenizer.decode(torch.topk(diff, 20).indices)\n",
    "    #     # diff = torch.norm(layer[:,-1,:], dim=1).item()\n",
    "    # layer = model.lm_head(layer)\n",
    "    # print(i, tokenizer.decode(layer.argmax(dim=-1)[0][-1]), diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257, 1280])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.wte.weight.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
