{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 10:36:26.415836: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 10:36:27.567126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-02 10:36:27.567151: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-02 10:36:32.668796: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 10:36:32.669011: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 10:36:32.669046: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f962a266c3214ea58763bb444d56f55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d03a86246fc4faba95126145db22fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38301ee86f3482fba6942713f6ab0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6954eae4654516b2403b9a4a1f8134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607015058e5c42fe9edd6143f4b8f311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2-large')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-large').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer.batch_encode_plus(['Barack Obama was the 44th president'], return_tensors='pt')\n",
    "output = model(\n",
    "    input_ids=tokenized['input_ids'].cuda(),\n",
    "    attention_mask=tokenized['attention_mask'].cuda(),\n",
    "    output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : -1\n",
      "1 : : The In If This a Only It What Not \" They All With A\n",
      " There ( Even When\n",
      "2 30  If The $30 This20 In: Not Even When It\n",
      " Only What They A There That \"\n",
      "3  Less  If The This Not It Only They Even That\n",
      " What When $20 In There Less30: All\n",
      "4  If  If The This They\n",
      " It In That A When What All There Only Not Even Since if $ We\n",
      "5  Logged  The If This\n",
      " When It They There What A All In Only That 1 We Not Even2030\n",
      "6  Logged  If The This\n",
      " When They A What20 It There30 In All We Not 1 Only Since40\n",
      "7  Logged  The If This\n",
      " When A In We Only There What It 12030 They ( Since All measured\n",
      "8  Logged  If This The When\n",
      " We Only They 1 In A There30 Since20 What It1 Not Because\n",
      "9  Logged  If When This The 1\n",
      "2030 Since1 Only\n",
      "\n",
      " In What$ $ They We There Because\n",
      "10  Logged  If 1 When20 $30 The1 Logged (\n",
      "\n",
      "$40 They\n",
      " Since-- This35 A\n",
      "11  Logged  $ 13020$3540 When If1 The50\n",
      " Logged 20 (\n",
      "\n",
      "-- 50 Currently\n",
      "12  Logged  1 $$1 The\n",
      "30 When 5050 If20 Logged A40 ( 20\n",
      "\n",
      "35 Currently\n",
      "13  Logged  The $ 1\n",
      " A1$ If 50 In When Logged What This Currently Current\n",
      "\n",
      " less 20 0\n",
      "14  Logged  1 $1 0\n",
      "$ A The 50 20 40 35•  If Logged3020 When (\n",
      "15 $  $ 1\n",
      " A1$ 0 The ( When 50 40 30 If• 35 203520\n",
      "16 $  $ A 1\n",
      "$ 01 The 50 40  When ( 35 20 3• If 30\n",
      "\n",
      "\n",
      "17 $  $$ A 1\n",
      "1 0  The ( When 50 40 less If30• I a Logged\n",
      "18 $  $$\n",
      " 11 A 0  ( 50 Rs less Currently 3 40•20 2030 £\n",
      "19 $  $$ 1\n",
      " 01 A 50 (  40 £ Rs= 20 Currently 8 $$ €0\n",
      "20 $  $$\n",
      " 1 0 A 501 The ( 40  5 20 8 3 4 Rs £ 9\n",
      "21 $  $ 1\n",
      " 0$1 A ( 50 2 3 The 4 8 5 7 \n",
      "\n",
      " 6 20\n",
      "22  $ \n",
      " 1 $ 0 ( A$1 2 3 \n",
      "\n",
      " 4 50 a 5 The http= 8\n",
      "23  $  1\n",
      " 0 $ 2 ( A 3 a 4\n",
      "\n",
      " 51 50 $ 7 \" 6 8\n",
      "24  1  1\n",
      " 0 $ 2 31 ( A 4 a 5 7\n",
      "\n",
      "$ 10 50 x 6 8\n",
      "25  1  1 2 0\n",
      " $ 31 4 5 a ( 10 7 A 6 8$\n",
      "\n",
      " 50 x\n",
      "26  1  1 2 0\n",
      " $ 3 41 10 5 a ( 7 6 A 8 9 50\n",
      "\n",
      " the\n",
      "27  1  1\n",
      " 2 0 $ 3 4 10 5 a (1 7 A 6\n",
      "\n",
      " 8 9 50 \"\n",
      "28  1  1\n",
      " 2 0 3 $ 4 10 5 ( 7 61 a\n",
      "\n",
      " A 8 9 The 20\n",
      "29  1  1\n",
      " 2 0 3 4 $ ( 5 6 10 71\n",
      "\n",
      " a The 8 A 9 the\n",
      "30  1  1\n",
      " 2 0 3 4 $1 10 ( 5 a 7 6 The 8\n",
      "\n",
      " A the 9\n",
      "31  1  1\n",
      " 2 0 3 ( 41 10 $ a 5 6 The 7\n",
      "\n",
      " the A - 8\n",
      "32  1 \n",
      " 1 2 0 ( 3 a $ 4 10 the1\n",
      "\n",
      " The 5 6 - 7 A 8\n",
      "33  1 \n",
      " 1 2 a ( 0 the 3 $ 4 The1\n",
      "\n",
      " 10 - 5 6 A 7.\n",
      "34  1 \n",
      " 1 2 a the ( 0 3 4 The $1 10 5 -\n",
      "\n",
      " 6 7 A.\n",
      "35  1 \n",
      " 1 the a 2 ( 3 0 The $ 4 101\n",
      "\n",
      " - 5 A \". 6\n",
      "36  1 \n",
      " 1 2 the ( a 0 3\n",
      "\n",
      " 10 The 4 51 - $ 6. 7 A\n"
     ]
    }
   ],
   "source": [
    "tokenized = tokenizer('president', return_tensors='pt')['input_ids'].cuda()\n",
    "president = model.transformer.wte(tokenized)[0]\n",
    "import torch\n",
    "for i, layer in enumerate(output.hidden_states):\n",
    "    diff = -1\n",
    "    if i > 0:\n",
    "        # diff = torch.cosine_similarity(layer[:,-1,:], output.hidden_states[i - 1][:,-1,:], dim=1).item()\n",
    "        diff = torch.cosine_similarity(layer[:,-1,:], model.transformer.wte.weight, dim=1)\n",
    "        diff = tokenizer.decode(torch.topk(diff, 20).indices)\n",
    "        # diff = torch.norm(layer[:,-1,:], dim=1).item()\n",
    "    layer = model.lm_head(layer)\n",
    "    print(i, tokenizer.decode(layer.argmax(dim=-1)[0][-1]), diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257, 1280])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.wte.weight.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
