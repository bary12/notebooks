{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "bi_encoder = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ms_marco (/home/ubuntu/.cache/huggingface/datasets/ms_marco/v2.1/2.1.0/b6a62715fa5219aea5275dd3556601004cd63945cb63e36e022f77bb3cbbca84)\n",
      "Loading cached shuffled indices for dataset at /home/ubuntu/.cache/huggingface/datasets/ms_marco/v2.1/2.1.0/b6a62715fa5219aea5275dd3556601004cd63945cb63e36e022f77bb3cbbca84/cache-89575f570aa58446.arrow\n",
      "Loading cached split indices for dataset at /home/ubuntu/.cache/huggingface/datasets/ms_marco/v2.1/2.1.0/b6a62715fa5219aea5275dd3556601004cd63945cb63e36e022f77bb3cbbca84/cache-82afc0a1dfe05f54.arrow and /home/ubuntu/.cache/huggingface/datasets/ms_marco/v2.1/2.1.0/b6a62715fa5219aea5275dd3556601004cd63945cb63e36e022f77bb3cbbca84/cache-839d92ed9c39c390.arrow\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset('ms_marco', 'v2.1', split='train[:100000]').shuffle(seed=42)\n",
    "dataset = dataset.train_test_split(test_size=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, encoding_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = 2 * encoding_dim\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim * 4, self.hidden_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim * 4, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, query, passage):\n",
    "        x = torch.cat([query, passage], dim=-1)\n",
    "        x = self.feed_forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = train['query']\n",
    "passages = [item['passages']['passage_text'][0] for item in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_encodings = bi_encoder.encode(queries, convert_to_tensor=True)\n",
    "passages_encodings = bi_encoder.encode(passages, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "passages_negative_encodings = list(itertools.islice(itertools.cycle(passages_encodings), 1, len(passages_encodings) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = []\n",
    "\n",
    "for i in range(len(queries_encodings)):\n",
    "    training_examples.append((queries_encodings[i], passages_encodings[i], 1))\n",
    "    training_examples.append((queries_encodings[i], passages_negative_encodings[i], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, iter 0, loss 0.0009935027360916137\n",
      "epoch 0, iter 1000, loss 0.989669047653675\n",
      "epoch 0, iter 2000, loss 0.9552439688444138\n",
      "epoch 0, iter 3000, loss 0.8340321342349053\n",
      "epoch 0, iter 4000, loss 0.6368400468826294\n",
      "epoch 0, iter 5000, loss 0.5128733741641045\n",
      "epoch 0, iter 6000, loss 0.4759647963047028\n",
      "epoch 0, iter 7000, loss 0.38384677821397784\n",
      "epoch 0, iter 8000, loss 0.3528786128759384\n",
      "epoch 0, iter 9000, loss 0.3324982855916023\n",
      "epoch 0, iter 10000, loss 0.30596018832921984\n",
      "epoch 0, iter 11000, loss 0.27760964566469193\n",
      "epoch 0, iter 12000, loss 0.29567714655399324\n",
      "epoch 0, iter 13000, loss 0.273961021900177\n",
      "epoch 0, iter 14000, loss 0.2603491520881653\n",
      "epoch 0, iter 15000, loss 0.23496199256181716\n",
      "epoch 0, iter 16000, loss 0.29490037977695466\n",
      "epoch 0, iter 17000, loss 0.22955643409490586\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m output \u001b[39m=\u001b[39m model(query\u001b[39m.\u001b[39mcuda(), passage\u001b[39m.\u001b[39mcuda())\n\u001b[1;32m      9\u001b[0m loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mmargin_ranking_loss(output, torch\u001b[39m.\u001b[39mzeros_like(output)\u001b[39m.\u001b[39mcuda(), torch\u001b[39m.\u001b[39mtensor([label])\u001b[39m.\u001b[39mcuda(), margin\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     11\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     12\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model(384).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "for epoch in range(1):\n",
    "    total_loss = 0\n",
    "    for i, (query, passage, label) in enumerate(training_examples):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(query.cuda(), passage.cuda())\n",
    "        loss = torch.nn.functional.margin_ranking_loss(output, torch.zeros_like(output).cuda(), torch.tensor([label]).cuda(), margin=1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 1000\n",
    "        if i % log_interval == 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            print(f'epoch {epoch}, iter {i}, loss {cur_loss}')\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataset['test']\n",
    "test_queries = test['query']\n",
    "test_passages = [item['passages']['passage_text'][0] for item in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '~/models/cross-embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries_encodings = bi_encoder.encode(test_queries, convert_to_tensor=True)\n",
    "test_passages_encodings = bi_encoder.encode(test_passages, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0759], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([2.0054], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([3.7806], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([2.2359], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([2.2724], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([2.9846], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([2.9599], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([3.1467], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([0.3648], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.2762], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(model(test_queries_encodings[i+0:i+1].cuda(), test_passages_encodings[i:i+1].cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 \n",
      "0.745\n"
     ]
    }
   ],
   "source": [
    "recall = 0\n",
    "for i in range(200):\n",
    "    print(i, end=' ')\n",
    "    query = test[i]['query']\n",
    "    query  = bi_encoder.encode(query, convert_to_tensor=True).cuda()\n",
    "    passage = [test[i] for i in range(200)]\n",
    "    passage = [x['passages'] for x in passage]\n",
    "    passage = [x['passage_text'][0] for x in passage]\n",
    "    passage = bi_encoder.encode(passage, convert_to_tensor=True).cuda()\n",
    "    # print(passage)\n",
    "    out = model(query.unsqueeze(0).repeat(200, 1), passage)\n",
    "    recall += 1.0 if i in list(torch.topk(out, 3, dim=0).indices[:, 0]) else 0.0\n",
    "\n",
    "print()\n",
    "print(recall / 200)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 384])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.unsqueeze(0).repeat(100, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94e278049994683a520774f5cb5ab5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6872524a85914862bfe8676a591df85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/62.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9dd664963846d8a48ac43c1ce42446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5142d38d8eb4166aa83456f616f4e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f013e977fb43c191bfc40a0e1654c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-2-v2', num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 \n",
      "0.92\n"
     ]
    }
   ],
   "source": [
    "recall = 0\n",
    "for i in range(200):\n",
    "    print(i, end=' ')\n",
    "    out = cross_encoder.predict([[test[i]['query'], test[j]['passages']['passage_text'][0]] for j in range(200)])\n",
    "    out = torch.from_numpy(out)\n",
    "    recall += 1.0 if i in list(torch.topk(out, 3).indices) else 0.0\n",
    "print()\n",
    "print(recall/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 \n",
      "0.955\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "recall = 0\n",
    "for i in range(200):\n",
    "    print(i, end=' ')\n",
    "    test_passages = [test[j]['passages']['passage_text'][0] for j in range(200)]\n",
    "    query_embedding = bi_encoder.encode(test[i]['query'], convert_to_tensor=True).cuda()\n",
    "    passage_embeddings = bi_encoder.encode(test_passages, convert_to_tensor=True).cuda()\n",
    "    cos_sim = torch.nn.functional.cosine_similarity(query_embedding.unsqueeze(0), passage_embeddings, dim=1)\n",
    "    # print(torch.topk(cos_sim, 1).indices)\n",
    "    recall += 1.0 if i in list(torch.topk(cos_sim, 3).indices) else 0.0\n",
    "print()\n",
    "print(recall/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': ['Yes,Augmentin comes in liquid form.'],\n",
       " 'passages': {'is_selected': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "  'passage_text': ['1 Upload failed. 2  We are experiencing some problems, please try again. 3  You can only upload files of type PNG, JPG, or JPEG. 4  You can only upload files of type 3GP, 3GPP, MP4, MOV, AVI, MPG, MPEG, or RM. 5  You can only upload photos smaller than 5 MB. 6  You can only upload videos smaller than 600MB.',\n",
       "   'Good dish for sharing, I don’t recommend does augmentin come in liquid form to eat on your own as you will get “ni” of does augmentin come in liquid form fast. 12 Hour does augmentin come in liquid form Braised Beef Short Ribs – $18. The braised beef short ribs was good. Very tender and juicy and I liked the potato pancake!',\n",
       "   '| Best Cheaps🔥 | ☀☀☀ does augmentin come in liquid form ☀☀☀. Free shipping, quality, privacy, secure. does augmentin come in liquid form,Big Discounts No Prescription Required. Fully licensed,. Get started now!',\n",
       "   'Amoxicillin (Pot Clavulana) - Augmentin. Amoxicillin is a laboratory made penicillin that is used to treat bacterial infections. It comes in several forms including a tablet, chewable tablet, capsule, pediatric drops or in a liquid form. It’s an antibiotic in the penicillin group of drugs and stops the growth of bacteria.',\n",
       "   '| Up to 50% Off🔥 | ☀☀☀ does augmentin come in liquid form ☀☀☀. Free Shipping, quality. Worldwide delivery does augmentin come in liquid form,Pill Shop, Cheap Prices. Free samples for all orders.. Get started now!',\n",
       "   'Heavy limbs respond to weight and wind forces by adding wood where needed for support. It is called “response growth” resulting in “reaction wood”, visible in does augmentin come in liquid form the muscular appearance of old trees.',\n",
       "   '| Up to 40% Off🔥 | ☀☀☀ does augmentin come in liquid form ☀☀☀. 2018 is 9 Best Erection Pills That Work! 100% does augmentin come in liquid form,Your health is important.. Get started now!',\n",
       "   'does augmentin come in liquid form does augmentin come in liquid form Employees in Health Sciences Center programs should follow the time tracking processes required in the TAL System.',\n",
       "   'Augmentin Description. Augmentin is an oral antibacterial combination consisting of amoxicillin and the beta‑lactamase inhibitor, clavulanate potassium (the potassium salt of clavulanic acid). Amoxicillin is an analog of ampicillin, derived from the basic penicillin nucleus, 6‑aminopenicillanic acid.',\n",
       "   'We offer products that help you solve your health problems. does augmentin come in liquid form,Know the uses, side effects, price, composition, substitutes,. Get started now! does augmentin come in liquid form'],\n",
       "  'url': ['https://answers.yahoo.com/question/index?qid=20080507074915AA27cNH',\n",
       "   'http://a-book.email/does-augmentin-come-in-liquid-form.d64',\n",
       "   'http://kurumsalsiteniz.com/augmentinincome/does-augmentin-come-in-liquid-form.usa?informcome=informcome',\n",
       "   'http://www.antibiotics-info.org/antibiotic-drugs.html',\n",
       "   'http://adverseeffectsofaciphex.simlifelot.com/does_augmentin_come_in_liquid_form.ppt?doesaugmentinform=liquidcomein',\n",
       "   'http://bonustou.network/does_augmentin_come_in_liquid_form.cheep?formcomedoes=liquidcomeaugmentin',\n",
       "   'http://comhelpany.com/forminaugmentin/does-augmentin-come-in-liquid-form.bing?augmentinincome=augmentinincome',\n",
       "   'http://adverseeffectsofaciphex.simlifelot.com/does_augmentin_come_in_liquid_form.ppt?doesaugmentinform=liquidcomein',\n",
       "   'https://www.drugs.com/pro/augmentin.html',\n",
       "   'http://a-book.email/does_augmentin_come_in_liquid_form.ca?inaugmentinform=doescomeliquid']},\n",
       " 'query': 'does augmentin come in liquid form',\n",
       " 'query_id': 1184253,\n",
       " 'query_type': 'DESCRIPTION',\n",
       " 'wellFormedAnswers': []}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
