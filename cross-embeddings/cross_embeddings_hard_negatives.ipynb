{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "bi_encoder = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ms_marco (/home/ubuntu/.cache/huggingface/datasets/ms_marco/v2.1/2.1.0/b6a62715fa5219aea5275dd3556601004cd63945cb63e36e022f77bb3cbbca84)\n",
      "Loading cached shuffled indices for dataset at /home/ubuntu/.cache/huggingface/datasets/ms_marco/v2.1/2.1.0/b6a62715fa5219aea5275dd3556601004cd63945cb63e36e022f77bb3cbbca84/cache-89575f570aa58446.arrow\n",
      "Loading cached split indices for dataset at /home/ubuntu/.cache/huggingface/datasets/ms_marco/v2.1/2.1.0/b6a62715fa5219aea5275dd3556601004cd63945cb63e36e022f77bb3cbbca84/cache-82afc0a1dfe05f54.arrow and /home/ubuntu/.cache/huggingface/datasets/ms_marco/v2.1/2.1.0/b6a62715fa5219aea5275dd3556601004cd63945cb63e36e022f77bb3cbbca84/cache-839d92ed9c39c390.arrow\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset('ms_marco', 'v2.1', split='train[:100000]').shuffle(seed=42)\n",
    "dataset = dataset.train_test_split(test_size=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset['train']\n",
    "\n",
    "queries = train['query']\n",
    "passages = [item['passages']['passage_text'][0] for item in train]\n",
    "\n",
    "queries_encodings = bi_encoder.encode(queries, convert_to_tensor=True)\n",
    "passages_encodings = bi_encoder.encode(passages, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, encoding_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = 2 * encoding_dim\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim * 2, self.hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim * 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, query, passage):\n",
    "        x = torch.cat([query, passage], dim=-1)\n",
    "        x = self.feed_forward(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "def generate_hard_negative(i):\n",
    "    query = dataset['train'][i]['query']\n",
    "    query_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
    "    hits = util.semantic_search(query_embedding, passages_encodings, top_k=2)\n",
    "    hits = hits[0]\n",
    "    if hits[0]['corpus_id'] == i:\n",
    "        return hits[1]['corpus_id']\n",
    "    else:\n",
    "        return hits[0]['corpus_id']\n",
    "    \n",
    "hard_negatives = [passages_encodings[generate_hard_negative(i)] for i in range(len(dataset['train']))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "passages_negative_encodings = list(itertools.islice(itertools.cycle(passages_encodings), 1, len(passages_encodings) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = []\n",
    "\n",
    "for i in range(len(queries_encodings)):\n",
    "    training_examples.append((queries_encodings[i], passages_encodings[i], 1))\n",
    "    # training_examples.append((queries_encodings[i], hard_negatives[i] if i % 2 == 0 else passages_negative_encodings[i], -1))\n",
    "    training_examples.append((queries_encodings[i], hard_negatives[i], -1))\n",
    "\n",
    "import random\n",
    "random.shuffle(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, iter 1000, loss 1.0169987825453282\n",
      "epoch 0, iter 2000, loss 0.9994893597066402\n",
      "epoch 0, iter 3000, loss 1.0008970820903778\n",
      "epoch 0, iter 4000, loss 1.0008500580489637\n",
      "epoch 0, iter 5000, loss 0.9996972008943558\n",
      "epoch 0, iter 6000, loss 1.0001417140364648\n",
      "epoch 0, iter 7000, loss 0.9953153203949332\n",
      "epoch 0, iter 8000, loss 1.0056423263326286\n",
      "epoch 0, iter 9000, loss 1.0022458066940307\n",
      "epoch 0, iter 10000, loss 0.9923955171108246\n",
      "epoch 0, iter 11000, loss 0.9957776233404875\n",
      "epoch 0, iter 12000, loss 0.997160516962409\n",
      "epoch 0, iter 13000, loss 0.992397736787796\n",
      "epoch 0, iter 14000, loss 0.9996234012544155\n",
      "epoch 0, iter 15000, loss 0.9974916656017303\n",
      "epoch 0, iter 16000, loss 0.9844332495480775\n",
      "epoch 0, iter 17000, loss 0.9845375006496906\n",
      "epoch 0, iter 18000, loss 0.992303868740797\n",
      "epoch 0, iter 19000, loss 0.9690869277082383\n",
      "epoch 0, iter 20000, loss 0.9769618330905214\n",
      "epoch 0, iter 21000, loss 0.9792052135504782\n",
      "epoch 0, iter 22000, loss 0.9756225202009082\n",
      "epoch 0, iter 23000, loss 0.9718851141268388\n",
      "epoch 0, iter 24000, loss 0.9628188512574416\n",
      "epoch 0, iter 25000, loss 0.9727214173013344\n",
      "epoch 0, iter 26000, loss 0.9845339332446456\n",
      "epoch 0, iter 27000, loss 0.9893202984659001\n",
      "epoch 0, iter 28000, loss 0.9801494770869613\n",
      "epoch 0, iter 29000, loss 0.9729336456358433\n",
      "epoch 0, iter 30000, loss 0.9923482268825173\n",
      "epoch 0, iter 31000, loss 0.9715641742274165\n",
      "epoch 0, iter 32000, loss 0.9728211162430235\n",
      "epoch 0, iter 33000, loss 0.9917237049639225\n",
      "epoch 0, iter 34000, loss 0.9693977574072778\n",
      "epoch 0, iter 35000, loss 0.9657711635869928\n",
      "epoch 0, iter 36000, loss 0.9581189578932244\n",
      "epoch 0, iter 37000, loss 0.9771310218796134\n",
      "epoch 0, iter 38000, loss 0.9552000197507441\n",
      "epoch 0, iter 39000, loss 0.9686772265983745\n",
      "epoch 0, iter 40000, loss 0.9773598501235247\n",
      "epoch 0, iter 41000, loss 0.9787129238322377\n",
      "epoch 0, iter 42000, loss 0.9749588890001177\n",
      "epoch 0, iter 43000, loss 0.9785250742286443\n",
      "epoch 0, iter 44000, loss 0.9672634041388519\n",
      "epoch 0, iter 45000, loss 0.9674045596010983\n",
      "epoch 0, iter 46000, loss 0.9695052156820894\n",
      "epoch 0, iter 47000, loss 0.9738301272345706\n",
      "epoch 0, iter 48000, loss 0.9725378072378226\n",
      "epoch 0, iter 49000, loss 0.9698650362463668\n",
      "epoch 0, iter 50000, loss 0.9529802654774394\n",
      "epoch 0, iter 51000, loss 0.9634387536086142\n",
      "epoch 0, iter 52000, loss 0.9704664059462957\n",
      "epoch 0, iter 53000, loss 0.9682217972418293\n",
      "epoch 0, iter 54000, loss 0.9570017781662755\n",
      "epoch 0, iter 55000, loss 0.9741165517990011\n",
      "epoch 0, iter 56000, loss 0.9554984437548556\n",
      "epoch 0, iter 57000, loss 0.9638496821867302\n",
      "epoch 0, iter 58000, loss 0.9707928182985633\n",
      "epoch 0, iter 59000, loss 0.9799190620128065\n",
      "epoch 0, iter 60000, loss 0.9658810272109695\n",
      "epoch 0, iter 61000, loss 0.9586343637176961\n",
      "epoch 0, iter 62000, loss 0.968957269153907\n",
      "epoch 0, iter 63000, loss 0.9562627874240279\n",
      "epoch 0, iter 64000, loss 0.9658560829292983\n",
      "epoch 0, iter 65000, loss 0.972838632915169\n",
      "epoch 0, iter 66000, loss 0.9684187309853732\n",
      "epoch 0, iter 67000, loss 0.9761679773554206\n",
      "epoch 0, iter 68000, loss 0.9510887448526919\n",
      "epoch 0, iter 69000, loss 0.9605693043326028\n",
      "epoch 0, iter 70000, loss 0.9670504207508639\n",
      "epoch 0, iter 71000, loss 0.9594419738212601\n",
      "epoch 0, iter 72000, loss 0.9665867942045443\n",
      "epoch 0, iter 73000, loss 0.962389876886271\n",
      "epoch 0, iter 74000, loss 0.9757228499278426\n",
      "epoch 0, iter 75000, loss 0.9711788487434387\n",
      "epoch 0, iter 76000, loss 0.9754446459040046\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, torch\u001b[39m.\u001b[39mtensor([label])\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mcuda())\n\u001b[1;32m     12\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 13\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     14\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     15\u001b[0m log_interval \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:68\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     67\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    235\u001b[0m          grads,\n\u001b[1;32m    236\u001b[0m          exp_avgs,\n\u001b[1;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    239\u001b[0m          state_steps,\n\u001b[1;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m func(params,\n\u001b[1;32m    301\u001b[0m      grads,\n\u001b[1;32m    302\u001b[0m      exp_avgs,\n\u001b[1;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    305\u001b[0m      state_steps,\n\u001b[1;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:353\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[39m# update step\u001b[39;00m\n\u001b[1;32m    351\u001b[0m step_t \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 353\u001b[0m \u001b[39mif\u001b[39;00m weight_decay \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    354\u001b[0m     grad \u001b[39m=\u001b[39m grad\u001b[39m.\u001b[39madd(param, alpha\u001b[39m=\u001b[39mweight_decay)\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_complex(param):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model(384).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "criterion = torch.nn.MSELoss()\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    for i, (query, passage, label) in enumerate(training_examples):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(query.cuda(), passage.cuda())\n",
    "        # loss = torch.nn.functional.margin_ranking_loss(output, torch.zeros_like(output).cuda(), torch.tensor([label]).cuda(), margin=1)\n",
    "        loss = criterion(output, torch.tensor([label]).float().cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 1000\n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            print(f'epoch {epoch}, iter {i}, loss {cur_loss}')\n",
    "            total_loss = 0\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '~/models/cross-embeddings.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
