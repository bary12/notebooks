{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "bi_encoder = SentenceTransformer('multi-qa-mpnet-base-dot-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ms_marco (/home/ubuntu/.cache/huggingface/datasets/ms_marco/v2.1/2.1.0/b6a62715fa5219aea5275dd3556601004cd63945cb63e36e022f77bb3cbbca84)\n",
      "Loading cached shuffled indices for dataset at /home/ubuntu/.cache/huggingface/datasets/ms_marco/v2.1/2.1.0/b6a62715fa5219aea5275dd3556601004cd63945cb63e36e022f77bb3cbbca84/cache-6f69f77053a477e7.arrow\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset('ms_marco', 'v2.1', split='train[:50000]').shuffle(seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = dataset['query'][:-1]\n",
    "answers = [dataset[i]['passages']['passage_text'][0] for i in range(len(dataset) - 1)]\n",
    "negatives = [dataset[i]['passages']['passage_text'][0] for i in range(1, len(dataset))]\n",
    "\n",
    "dataset = datasets.Dataset.from_dict({'query': queries, 'answer': answers, 'negative': negatives}).with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b20dae15bb74ceab7dd8effc6e9a7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_embeddings(batch):\n",
    "    query_embeddings = bi_encoder.encode(batch['query'], convert_to_tensor=True)\n",
    "    answer_embeddings = bi_encoder.encode(batch['answer'], convert_to_tensor=True)\n",
    "    negative_embeddings = bi_encoder.encode(batch['negative'], convert_to_tensor=True)\n",
    "    return {\n",
    "        'query': batch['query'],\n",
    "        'answer': batch['answer'],\n",
    "        'query_embeddings': query_embeddings,\n",
    "        'answer_embeddings': answer_embeddings,\n",
    "        'negative_embeddings': negative_embeddings\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(compute_embeddings, batched=True, batch_size=32, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.input = torch.nn.Linear(768, 768)\n",
    "        self.hidden = torch.nn.Linear(768, 768)\n",
    "        self.hidden2 = torch.nn.Linear(768, 768)\n",
    "        self.output = torch.nn.Linear(768, 768)\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def forward(self, query_embeddings, answer_embeddings = None, negative_embeddings = None):\n",
    "        x = torch.nn.functional.relu(self.input(query_embeddings))\n",
    "        x = torch.nn.functional.relu(self.hidden(x))\n",
    "        x = torch.nn.functional.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        if answer_embeddings is None:\n",
    "            return x\n",
    "        if negative_embeddings is None:\n",
    "            return torch.cdist(x, answer_embeddings)\n",
    "        return torch.cdist(x, answer_embeddings)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            torch.nn.init.eye_(module.weight.data)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset['train'], batch_size=1)\n",
    "test_loader = torch.utils.data.DataLoader(dataset['test'], batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/44999 (0%)]\tLoss: 0.009952\n",
      "Train Epoch: 0 [500/44999 (1%)]\tLoss: 5.100455\n",
      "Train Epoch: 0 [1000/44999 (2%)]\tLoss: 5.178916\n",
      "Train Epoch: 0 [1500/44999 (3%)]\tLoss: 5.135371\n",
      "Train Epoch: 0 [2000/44999 (4%)]\tLoss: 5.136087\n",
      "Train Epoch: 0 [2500/44999 (6%)]\tLoss: 5.110249\n",
      "Train Epoch: 0 [3000/44999 (7%)]\tLoss: 5.124282\n",
      "Train Epoch: 0 [3500/44999 (8%)]\tLoss: 5.173331\n",
      "Train Epoch: 0 [4000/44999 (9%)]\tLoss: 5.137742\n",
      "Train Epoch: 0 [4500/44999 (10%)]\tLoss: 5.171744\n",
      "Train Epoch: 0 [5000/44999 (11%)]\tLoss: 5.162171\n",
      "Train Epoch: 0 [5500/44999 (12%)]\tLoss: 5.180902\n",
      "Train Epoch: 0 [6000/44999 (13%)]\tLoss: 5.174512\n",
      "Train Epoch: 0 [6500/44999 (14%)]\tLoss: 5.103578\n",
      "Train Epoch: 0 [7000/44999 (16%)]\tLoss: 5.153427\n",
      "Train Epoch: 0 [7500/44999 (17%)]\tLoss: 5.117138\n",
      "Train Epoch: 0 [8000/44999 (18%)]\tLoss: 5.185576\n",
      "Train Epoch: 0 [8500/44999 (19%)]\tLoss: 5.157793\n",
      "Train Epoch: 0 [9000/44999 (20%)]\tLoss: 5.138011\n",
      "Train Epoch: 0 [9500/44999 (21%)]\tLoss: 5.157519\n",
      "Train Epoch: 0 [10000/44999 (22%)]\tLoss: 5.139519\n",
      "Train Epoch: 0 [10500/44999 (23%)]\tLoss: 5.139909\n",
      "Train Epoch: 0 [11000/44999 (24%)]\tLoss: 5.208519\n",
      "Train Epoch: 0 [11500/44999 (26%)]\tLoss: 5.192112\n",
      "Train Epoch: 0 [12000/44999 (27%)]\tLoss: 5.120397\n",
      "Train Epoch: 0 [12500/44999 (28%)]\tLoss: 5.195751\n",
      "Train Epoch: 0 [13000/44999 (29%)]\tLoss: 5.154735\n",
      "Train Epoch: 0 [13500/44999 (30%)]\tLoss: 5.185224\n",
      "Train Epoch: 0 [14000/44999 (31%)]\tLoss: 5.133698\n",
      "Train Epoch: 0 [14500/44999 (32%)]\tLoss: 5.169834\n",
      "Train Epoch: 0 [15000/44999 (33%)]\tLoss: 5.143605\n",
      "Train Epoch: 0 [15500/44999 (34%)]\tLoss: 5.123959\n",
      "Train Epoch: 0 [16000/44999 (36%)]\tLoss: 5.150812\n",
      "Train Epoch: 0 [16500/44999 (37%)]\tLoss: 5.100285\n",
      "Train Epoch: 0 [17000/44999 (38%)]\tLoss: 5.175943\n",
      "Train Epoch: 0 [17500/44999 (39%)]\tLoss: 5.124383\n",
      "Train Epoch: 0 [18000/44999 (40%)]\tLoss: 5.134235\n",
      "Train Epoch: 0 [18500/44999 (41%)]\tLoss: 5.147850\n",
      "Train Epoch: 0 [19000/44999 (42%)]\tLoss: 5.180995\n",
      "Train Epoch: 0 [19500/44999 (43%)]\tLoss: 5.133378\n",
      "Train Epoch: 0 [20000/44999 (44%)]\tLoss: 5.102595\n",
      "Train Epoch: 0 [20500/44999 (46%)]\tLoss: 5.132384\n",
      "Train Epoch: 0 [21000/44999 (47%)]\tLoss: 5.104047\n",
      "Train Epoch: 0 [21500/44999 (48%)]\tLoss: 5.129974\n",
      "Train Epoch: 0 [22000/44999 (49%)]\tLoss: 5.150731\n",
      "Train Epoch: 0 [22500/44999 (50%)]\tLoss: 5.210849\n",
      "Train Epoch: 0 [23000/44999 (51%)]\tLoss: 5.148872\n",
      "Train Epoch: 0 [23500/44999 (52%)]\tLoss: 5.103325\n",
      "Train Epoch: 0 [24000/44999 (53%)]\tLoss: 5.210572\n",
      "Train Epoch: 0 [24500/44999 (54%)]\tLoss: 5.170060\n",
      "Train Epoch: 0 [25000/44999 (56%)]\tLoss: 5.148584\n",
      "Train Epoch: 0 [25500/44999 (57%)]\tLoss: 5.068450\n",
      "Train Epoch: 0 [26000/44999 (58%)]\tLoss: 5.158394\n",
      "Train Epoch: 0 [26500/44999 (59%)]\tLoss: 5.109324\n",
      "Train Epoch: 0 [27000/44999 (60%)]\tLoss: 5.081988\n",
      "Train Epoch: 0 [27500/44999 (61%)]\tLoss: 5.166521\n",
      "Train Epoch: 0 [28000/44999 (62%)]\tLoss: 5.135635\n",
      "Train Epoch: 0 [28500/44999 (63%)]\tLoss: 5.090890\n",
      "Train Epoch: 0 [29000/44999 (64%)]\tLoss: 5.132086\n",
      "Train Epoch: 0 [29500/44999 (66%)]\tLoss: 5.138045\n",
      "Train Epoch: 0 [30000/44999 (67%)]\tLoss: 5.153499\n",
      "Train Epoch: 0 [30500/44999 (68%)]\tLoss: 5.145865\n",
      "Train Epoch: 0 [31000/44999 (69%)]\tLoss: 5.141667\n",
      "Train Epoch: 0 [31500/44999 (70%)]\tLoss: 5.095937\n",
      "Train Epoch: 0 [32000/44999 (71%)]\tLoss: 5.146306\n",
      "Train Epoch: 0 [32500/44999 (72%)]\tLoss: 5.123414\n",
      "Train Epoch: 0 [33000/44999 (73%)]\tLoss: 5.235143\n",
      "Train Epoch: 0 [33500/44999 (74%)]\tLoss: 5.154184\n",
      "Train Epoch: 0 [34000/44999 (76%)]\tLoss: 5.167238\n",
      "Train Epoch: 0 [34500/44999 (77%)]\tLoss: 5.104949\n",
      "Train Epoch: 0 [35000/44999 (78%)]\tLoss: 5.191749\n",
      "Train Epoch: 0 [35500/44999 (79%)]\tLoss: 5.146313\n",
      "Train Epoch: 0 [36000/44999 (80%)]\tLoss: 5.174661\n",
      "Train Epoch: 0 [36500/44999 (81%)]\tLoss: 5.187200\n",
      "Train Epoch: 0 [37000/44999 (82%)]\tLoss: 5.144984\n",
      "Train Epoch: 0 [37500/44999 (83%)]\tLoss: 5.134857\n",
      "Train Epoch: 0 [38000/44999 (84%)]\tLoss: 5.157208\n",
      "Train Epoch: 0 [38500/44999 (86%)]\tLoss: 5.124210\n",
      "Train Epoch: 0 [39000/44999 (87%)]\tLoss: 5.158797\n",
      "Train Epoch: 0 [39500/44999 (88%)]\tLoss: 5.122243\n",
      "Train Epoch: 0 [40000/44999 (89%)]\tLoss: 5.167039\n",
      "Train Epoch: 0 [40500/44999 (90%)]\tLoss: 5.114833\n",
      "Train Epoch: 0 [41000/44999 (91%)]\tLoss: 5.068446\n",
      "Train Epoch: 0 [41500/44999 (92%)]\tLoss: 5.144013\n",
      "Train Epoch: 0 [42000/44999 (93%)]\tLoss: 5.044429\n",
      "Train Epoch: 0 [42500/44999 (94%)]\tLoss: 5.147051\n",
      "Train Epoch: 0 [43000/44999 (96%)]\tLoss: 5.135908\n",
      "Train Epoch: 0 [43500/44999 (97%)]\tLoss: 5.156894\n",
      "Train Epoch: 0 [44000/44999 (98%)]\tLoss: 5.162086\n",
      "Train Epoch: 0 [44500/44999 (99%)]\tLoss: 5.137158\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "model.train()\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-6, betas=(0.9,0.999), eps=1e-08)\n",
    "\n",
    "batch_loss = 0\n",
    "\n",
    "for epoch in range(1):\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        query_embeddings = batch['query_embeddings'].to(device)\n",
    "        answer_embeddings = batch['answer_embeddings'].to(device)\n",
    "        negative_embeddings = batch['answer_embeddings'].to(device)\n",
    "        loss = model(query_embeddings, answer_embeddings, negative_embeddings)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        batch_loss += loss.item()\n",
    "        if batch_idx % 500 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * query_embeddings.shape[0], len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), batch_loss / 500))\n",
    "            batch_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 5.171576\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "iterations = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        query_embeddings = batch['query_embeddings'].to(device)\n",
    "        answer_embeddings = batch['answer_embeddings'].to(device)\n",
    "        loss = model(query_embeddings, answer_embeddings)\n",
    "        test_loss += loss.item()\n",
    "        iterations += 1\n",
    "\n",
    "print('Test set: Average loss: {:.6f}'.format(test_loss / iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '~/models/qa-autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.3928]], device='cuda:0', grad_fn=<CdistBackward0>)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(dataset['test'][1]['query_embeddings'].unsqueeze(0).cuda(), dataset['test'][1]['answer_embeddings'].unsqueeze(0).cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.6375]], device='cuda:0', grad_fn=<CdistBackward0>)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(dataset['test'][1]['query_embeddings'].unsqueeze(0).cuda(), dataset['test'][5]['answer_embeddings'].unsqueeze(0).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - F.cosine_similarity(torch.tensor([[1.0, -1.0]]), torch.tensor([[1.0, 1.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.80%\n"
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "correct = 0\n",
    "for i in range(n):\n",
    "    dist = torch.norm(model(dataset['test'][i]['query_embeddings'].cuda()) - dataset['test']['answer_embeddings'].cuda(), dim=1)\n",
    "    if i in dist.topk(10, largest=False).indices:\n",
    "        correct += 1\n",
    "\n",
    "print('Accuracy: {:.2f}%'.format(correct / n * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[454], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[0;32m----> 4\u001b[0m     dist \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnorm(dataset[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m][i][\u001b[39m'\u001b[39m\u001b[39mquery_embeddings\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mcuda() \u001b[39m-\u001b[39m dataset[\u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39manswer_embeddings\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mcuda(), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39min\u001b[39;00m dist\u001b[39m.\u001b[39mtopk(\u001b[39m10\u001b[39m, largest\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mindices:\n\u001b[1;32m      6\u001b[0m         correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py:2590\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2588\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):  \u001b[39m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2589\u001b[0m     \u001b[39m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2590\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(\n\u001b[1;32m   2591\u001b[0m         key,\n\u001b[1;32m   2592\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py:2574\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2572\u001b[0m format_kwargs \u001b[39m=\u001b[39m format_kwargs \u001b[39mif\u001b[39;00m format_kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m   2573\u001b[0m formatter \u001b[39m=\u001b[39m get_formatter(format_type, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> 2574\u001b[0m pa_subtable \u001b[39m=\u001b[39m query_table(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data, key, indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indices \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indices \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   2575\u001b[0m formatted_output \u001b[39m=\u001b[39m format_table(\n\u001b[1;32m   2576\u001b[0m     pa_subtable, key, formatter\u001b[39m=\u001b[39mformatter, format_columns\u001b[39m=\u001b[39mformat_columns, output_all_columns\u001b[39m=\u001b[39moutput_all_columns\n\u001b[1;32m   2577\u001b[0m )\n\u001b[1;32m   2578\u001b[0m \u001b[39mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:593\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    591\u001b[0m     pa_subtable \u001b[39m=\u001b[39m _query_table(table, key)\n\u001b[1;32m    592\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 593\u001b[0m     pa_subtable \u001b[39m=\u001b[39m _query_table_with_indices_mapping(table, key, indices\u001b[39m=\u001b[39;49mindices)\n\u001b[1;32m    594\u001b[0m \u001b[39mreturn\u001b[39;00m pa_subtable\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:73\u001b[0m, in \u001b[0;36m_query_table_with_indices_mapping\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     72\u001b[0m     table \u001b[39m=\u001b[39m table\u001b[39m.\u001b[39mselect([key])\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m _query_table(table, indices\u001b[39m.\u001b[39;49mcolumn(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mto_pylist())\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Iterable):\n\u001b[1;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m _query_table(table, [indices\u001b[39m.\u001b[39mfast_slice(i, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcolumn(\u001b[39m0\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mas_py() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m key])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:100\u001b[0m, in \u001b[0;36m_query_table\u001b[0;34m(table, key)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39mtable\u001b[39m.\u001b[39mslice(\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m     99\u001b[0m     \u001b[39m# don't use pyarrow.Table.take even for pyarrow >=1.0 (see https://issues.apache.org/jira/browse/ARROW-9773)\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39;49mfast_gather(key \u001b[39m%\u001b[39;49m table\u001b[39m.\u001b[39;49mnum_rows)\n\u001b[1;32m    102\u001b[0m _raise_bad_key_type(key)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/table.py:120\u001b[0m, in \u001b[0;36mIndexedTableMixin.fast_gather\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIndices must be non-empty\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m batch_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msearchsorted(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offsets, indices, side\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mright\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39mTable\u001b[39m.\u001b[39mfrom_batches(\n\u001b[0;32m--> 120\u001b[0m     [\n\u001b[1;32m    121\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batches[batch_idx]\u001b[39m.\u001b[39mslice(i \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offsets[batch_idx], \u001b[39m1\u001b[39m)\n\u001b[1;32m    122\u001b[0m         \u001b[39mfor\u001b[39;00m batch_idx, i \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(batch_indices, indices)\n\u001b[1;32m    123\u001b[0m     ],\n\u001b[1;32m    124\u001b[0m     schema\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_schema,\n\u001b[1;32m    125\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/table.py:121\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIndices must be non-empty\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m batch_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msearchsorted(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offsets, indices, side\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mright\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39mTable\u001b[39m.\u001b[39mfrom_batches(\n\u001b[1;32m    120\u001b[0m     [\n\u001b[0;32m--> 121\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batches[batch_idx]\u001b[39m.\u001b[39;49mslice(i \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_offsets[batch_idx], \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m         \u001b[39mfor\u001b[39;00m batch_idx, i \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(batch_indices, indices)\n\u001b[1;32m    123\u001b[0m     ],\n\u001b[1;32m    124\u001b[0m     schema\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_schema,\n\u001b[1;32m    125\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "correct = 0\n",
    "for i in range(n):\n",
    "    dist = torch.norm(dataset['test'][i]['query_embeddings'].cuda() - dataset['test']['answer_embeddings'].cuda(), dim=1)\n",
    "    if i in dist.topk(10, largest=False).indices:\n",
    "        correct += 1\n",
    "\n",
    "print('Accuracy: {:.2f}%'.format(correct / n * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('input.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 9.2294e-01, -2.3622e-03, -8.9584e-03,  ..., -6.7652e-03,\n",
       "           -3.5332e-03, -6.2148e-04],\n",
       "          [-2.6781e-03,  9.1454e-01, -1.7326e-02,  ..., -6.3215e-03,\n",
       "           -2.9847e-03, -5.9126e-03],\n",
       "          [ 4.1321e-05, -7.0142e-04,  9.7410e-01,  ..., -1.4900e-05,\n",
       "           -2.2402e-03, -4.3997e-03],\n",
       "          ...,\n",
       "          [ 1.1665e-03, -1.1044e-04, -1.0033e-02,  ...,  9.2585e-01,\n",
       "            3.5307e-03,  2.4766e-03],\n",
       "          [ 4.3231e-04, -4.8298e-04, -8.5984e-03,  ..., -3.2194e-03,\n",
       "            9.3160e-01, -5.7781e-03],\n",
       "          [ 3.3451e-03, -1.5221e-03, -4.9937e-03,  ..., -3.3635e-03,\n",
       "           -1.5077e-03,  9.3447e-01]], device='cuda:0', requires_grad=True)),\n",
       " ('input.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 7.4603e-03,  1.8334e-02,  3.4891e-03,  6.6953e-03,  6.9675e-03,\n",
       "           7.2083e-03,  2.9177e-03,  2.1013e-03,  9.2054e-03, -9.5998e-05,\n",
       "           5.9117e-03,  6.7753e-03,  7.2387e-03,  9.2988e-03,  7.1064e-03,\n",
       "           7.6764e-03,  3.0157e-03,  1.2117e-03,  8.5667e-03,  7.2980e-03,\n",
       "           5.9435e-03,  3.9240e-03,  7.4758e-03,  2.0307e-03,  1.0104e-02,\n",
       "           4.2241e-03,  2.5245e-03,  2.7507e-03,  7.7604e-03,  7.2850e-03,\n",
       "           7.9439e-03,  3.8468e-03,  7.1659e-03,  3.8342e-03,  0.0000e+00,\n",
       "           4.3533e-03,  1.0272e-03,  3.6024e-03,  1.0277e-02,  3.7048e-03,\n",
       "           1.0752e-02,  9.4707e-03,  7.8196e-03,  4.7275e-03,  5.6006e-03,\n",
       "           9.0950e-03,  5.0696e-03,  1.0879e-02,  4.7209e-03,  2.3722e-03,\n",
       "          -3.0287e-03,  9.5006e-03,  7.7994e-03,  3.6762e-03,  6.2068e-03,\n",
       "           7.7945e-03,  4.8627e-03,  7.4064e-03,  5.3963e-03,  1.1317e-02,\n",
       "           5.5552e-03,  3.8752e-03,  3.6338e-03,  3.6005e-03,  9.3419e-03,\n",
       "           7.9319e-03,  3.2917e-03,  4.8151e-03,  2.5334e-03,  5.4361e-03,\n",
       "           8.1095e-03,  4.5984e-03,  3.2196e-03,  4.9844e-03,  6.2095e-03,\n",
       "           1.2189e-02,  2.0243e-03,  5.2584e-03,  5.9514e-03,  3.3395e-03,\n",
       "           7.3287e-03,  6.4717e-03,  4.8904e-03,  5.3916e-03,  9.6806e-03,\n",
       "           7.2574e-03,  3.9077e-03,  1.4874e-03,  4.2704e-03,  6.3782e-03,\n",
       "           9.5615e-03,  1.7625e-03,  3.4690e-03,  3.1849e-03,  7.4957e-03,\n",
       "           6.3045e-03,  2.6013e-03,  8.2365e-03,  5.5863e-03,  7.3721e-03,\n",
       "           7.2351e-03,  2.5842e-03,  8.9262e-03,  2.6379e-03,  4.2112e-03,\n",
       "           8.8788e-03,  5.6121e-03,  1.0528e-02,  4.0156e-03,  5.4771e-03,\n",
       "           6.5478e-03,  7.7812e-04,  5.8290e-03,  9.4870e-03,  1.2282e-02,\n",
       "           5.3614e-03,  8.3707e-03,  6.3944e-03,  9.2592e-03,  1.6500e-03,\n",
       "           1.2396e-02,  4.0804e-03,  3.7427e-03,  3.3126e-04,  5.2240e-03,\n",
       "           8.0374e-03,  7.9577e-03,  2.4408e-03,  4.4518e-03,  1.0510e-02,\n",
       "           1.3495e-03,  3.5329e-03,  6.0954e-03,  7.0175e-03,  6.3867e-03,\n",
       "           7.6494e-03,  2.1427e-03,  4.4886e-03,  7.9142e-03,  4.2672e-03,\n",
       "           3.4426e-03,  5.7000e-03,  3.2976e-03,  2.5512e-03,  7.9948e-03,\n",
       "           9.5675e-03,  3.5116e-03,  8.6452e-03,  4.7777e-03,  1.2923e-03,\n",
       "           8.1103e-03,  6.9847e-03,  8.8884e-03, -2.9524e-03,  2.4400e-03,\n",
       "           3.2940e-03,  5.5760e-03,  6.8442e-03,  4.3334e-03,  9.5910e-03,\n",
       "           8.6929e-04,  4.4223e-03,  9.0977e-03,  4.6019e-03,  6.9036e-03,\n",
       "           2.2668e-03,  1.1120e-02,  7.5610e-03,  8.5745e-03,  7.2959e-03,\n",
       "           6.7899e-03,  4.1993e-03,  4.6417e-03,  4.9257e-03,  4.5509e-03,\n",
       "           1.1154e-02,  6.8434e-03,  1.4444e-02,  1.3270e-02,  7.1889e-03,\n",
       "           4.8967e-03,  1.1880e-02,  2.5889e-03,  7.8281e-03,  1.0952e-02,\n",
       "           3.2843e-03,  6.6787e-03,  6.7632e-03,  2.9744e-03,  3.2654e-03,\n",
       "           5.7356e-03,  7.4768e-03,  1.0848e-02,  2.7725e-03,  3.7612e-03,\n",
       "           3.5605e-03,  2.6504e-03,  7.0078e-03,  2.6252e-03,  4.2290e-03,\n",
       "           5.7646e-03,  4.8976e-03,  6.3190e-03,  1.0392e-02,  5.4849e-03,\n",
       "           5.3290e-03,  9.3997e-03,  8.2370e-03,  1.1991e-02,  4.9289e-03,\n",
       "           9.3756e-03,  4.9329e-03,  7.8275e-03,  3.2226e-03,  1.7215e-03,\n",
       "           6.2036e-03, -2.7036e-03,  2.0273e-03,  5.9769e-03,  6.1229e-03,\n",
       "           6.2761e-03,  9.8081e-03,  1.1234e-02,  2.5048e-03,  9.8404e-03,\n",
       "           8.0757e-03,  3.8779e-03,  5.2528e-03,  6.4445e-03,  3.9566e-03,\n",
       "           8.7941e-04,  3.1051e-03, -2.0184e-04,  3.9602e-03,  9.9990e-03,\n",
       "           7.6963e-03,  5.8814e-03,  4.3304e-03,  3.0210e-03,  1.2944e-02,\n",
       "           3.0868e-03,  9.2228e-03,  2.9205e-03,  1.9513e-03,  7.8361e-03,\n",
       "           1.8768e-03,  4.5209e-03,  3.7497e-03,  3.5582e-03,  7.2125e-03,\n",
       "           7.0535e-03,  2.5966e-03,  6.4760e-03,  1.0219e-02,  3.1593e-03,\n",
       "           6.8493e-03,  8.4501e-03,  5.5205e-03,  1.0810e-02,  5.7487e-03,\n",
       "           6.6850e-03,  3.9522e-03,  2.9826e-04,  3.2388e-03,  4.7261e-03,\n",
       "           4.8023e-03,  5.6630e-03,  9.3943e-03,  9.8748e-04, -1.3780e-03,\n",
       "           5.5409e-03,  4.2368e-03,  5.9298e-03,  6.2710e-03,  5.9210e-05,\n",
       "           4.8028e-03,  1.0891e-02,  2.4265e-03,  4.5237e-03,  3.7239e-03,\n",
       "           8.9665e-03,  1.1580e-02,  4.7534e-03,  2.9313e-03,  4.0528e-03,\n",
       "           4.2853e-03,  5.2325e-03,  1.0894e-02,  5.5544e-03,  1.1059e-02,\n",
       "           6.8697e-03,  6.4137e-03,  1.3656e-03,  7.9302e-03,  6.3780e-03,\n",
       "           3.8499e-03,  9.5252e-03, -5.1969e-04,  5.3042e-03,  5.7926e-03,\n",
       "           5.5278e-03,  9.3327e-03,  3.0489e-03, -2.4095e-03,  7.0461e-03,\n",
       "           8.0122e-03,  5.4179e-03,  8.9744e-03,  7.7373e-03,  8.8333e-03,\n",
       "           1.0765e-02,  1.1924e-03,  2.0037e-03,  1.1920e-02,  2.5017e-03,\n",
       "           4.1791e-03,  1.1787e-02,  9.0230e-03,  2.1420e-03,  1.3515e-02,\n",
       "           6.1656e-03,  5.2796e-03,  2.6706e-03,  6.9087e-03,  5.9846e-03,\n",
       "           9.6592e-03,  4.1537e-03,  6.2986e-03,  9.1310e-03,  4.0540e-03,\n",
       "           2.0254e-04,  6.4856e-03,  5.9321e-03,  5.5899e-03,  1.0437e-02,\n",
       "           4.7342e-03,  6.4858e-03,  1.3671e-02,  4.6919e-03,  6.5592e-03,\n",
       "           4.0095e-03,  8.5032e-03,  5.8612e-03,  8.2734e-03,  1.2524e-02,\n",
       "           9.3454e-03,  1.2117e-02,  3.0016e-03,  9.2854e-03,  6.1353e-03,\n",
       "           8.9195e-03,  5.9605e-03,  2.6662e-03,  6.7623e-03,  3.5287e-03,\n",
       "           9.1740e-03,  3.8623e-03,  1.0056e-02,  6.4753e-03,  6.7346e-03,\n",
       "           7.7130e-03,  6.3580e-03,  5.1344e-03,  8.4085e-03,  9.5164e-03,\n",
       "           3.9554e-03,  2.0837e-03,  2.1821e-03,  3.4091e-03,  6.8533e-03,\n",
       "           7.8024e-03,  1.3794e-03,  8.8968e-03,  6.1629e-04,  2.3806e-03,\n",
       "           9.9263e-03,  3.5051e-03,  8.1015e-03,  1.0334e-02,  3.8561e-03,\n",
       "           5.1048e-03,  7.0864e-03,  1.0423e-02,  3.3112e-03,  7.9953e-03,\n",
       "           5.3964e-03,  5.4286e-03,  6.4366e-03,  7.3528e-03,  8.8557e-03,\n",
       "           6.2209e-03,  1.0168e-02,  9.4448e-03,  7.6115e-03,  1.4631e-05,\n",
       "           3.9791e-03,  7.5330e-03,  5.6708e-03,  7.1584e-03, -2.0174e-03,\n",
       "           4.5927e-03,  5.1673e-03,  7.5577e-03,  3.3437e-03,  3.1409e-03,\n",
       "           1.0021e-02,  6.3119e-03,  4.3056e-03,  1.0536e-02,  9.6465e-03,\n",
       "           6.0276e-03,  5.0948e-03,  9.2689e-03,  2.2240e-03,  6.0212e-03,\n",
       "           9.6036e-03,  3.4371e-03,  4.1753e-03,  6.5529e-03,  1.0730e-02,\n",
       "           9.9489e-03,  1.7986e-03,  5.5942e-03,  6.4179e-03,  4.2610e-03,\n",
       "           3.5935e-03,  1.0463e-02,  8.8539e-03,  3.5577e-03,  2.8226e-03,\n",
       "           4.8531e-03,  5.2009e-03,  6.4215e-03,  1.0988e-02,  6.4772e-03,\n",
       "           7.1415e-03,  8.2116e-03,  9.7276e-03,  7.5135e-03,  5.6058e-03,\n",
       "           6.3712e-03,  5.5303e-03, -7.6887e-05,  1.8406e-03,  6.3986e-03,\n",
       "           1.0693e-02,  2.6208e-03,  7.8544e-03,  6.2322e-03,  7.0467e-03,\n",
       "           3.0811e-03,  7.3646e-03,  9.6654e-03,  6.0218e-03,  9.6148e-03,\n",
       "           5.1898e-03,  1.0405e-02,  5.7041e-03,  5.6824e-03,  9.7735e-03,\n",
       "           1.2420e-03,  2.5547e-04,  2.4461e-03,  2.1312e-03,  4.4007e-03,\n",
       "           1.3180e-02,  9.4717e-03,  1.2981e-02,  2.3494e-03,  7.2733e-03,\n",
       "           6.7031e-03,  2.8475e-03,  2.8271e-03,  4.2510e-03,  6.9391e-03,\n",
       "           5.0107e-03,  5.0809e-03,  1.0210e-02,  4.5282e-03,  1.4751e-03,\n",
       "           8.8481e-03,  9.3103e-03,  1.6775e-03,  9.0567e-03, -1.6742e-03,\n",
       "           2.0083e-03,  5.0370e-03,  3.8993e-03,  3.9738e-03,  5.5379e-03,\n",
       "           1.0032e-02,  7.3698e-03,  4.8691e-03,  1.2568e-02,  4.2576e-03,\n",
       "           8.4130e-03,  1.2654e-02,  1.0909e-02,  1.1707e-02,  6.8878e-03,\n",
       "           4.7682e-03,  3.3341e-03,  1.0331e-03,  6.2286e-03,  4.2592e-03,\n",
       "           7.3484e-03,  1.3763e-03,  5.0756e-03,  5.0269e-03,  6.8865e-03,\n",
       "           1.9130e-03,  1.8653e-03,  8.9589e-03,  1.4161e-02,  2.6452e-03,\n",
       "           6.9563e-03,  1.0763e-02,  8.7443e-03, -1.7609e-07,  6.0790e-03,\n",
       "           4.7888e-03, -1.8937e-03,  5.8711e-03,  3.9977e-03,  6.2961e-03,\n",
       "           3.4870e-03,  4.6208e-03,  4.1797e-03,  3.8324e-03,  2.8055e-03,\n",
       "           8.2653e-03,  6.0872e-03,  1.2328e-02,  7.1478e-03,  6.2213e-03,\n",
       "           1.0323e-02,  8.9180e-03,  1.5313e-02,  3.4935e-03,  8.4922e-03,\n",
       "           9.5935e-03,  3.4709e-03,  7.3631e-03,  8.0899e-04,  2.6449e-03,\n",
       "           7.1048e-03,  6.9806e-03,  1.0084e-02,  2.9906e-03,  1.0463e-02,\n",
       "           4.1175e-04,  8.9359e-03,  7.3783e-03,  5.9175e-03,  5.9235e-03,\n",
       "          -6.2792e-04,  4.4925e-03,  7.6830e-03,  3.9081e-03,  8.1842e-03,\n",
       "           8.9638e-03,  8.3869e-03,  2.2116e-03, -1.8808e-03,  4.6481e-03,\n",
       "           6.6340e-03,  9.7118e-04,  3.1575e-03, -7.0906e-04,  1.6506e-04,\n",
       "           5.5518e-03,  5.0577e-03,  2.9467e-03,  3.5968e-03,  5.9041e-04,\n",
       "           3.2124e-03,  9.5979e-03,  4.0799e-04,  5.5295e-03,  5.9205e-03,\n",
       "           5.0001e-03,  4.6133e-03,  5.5995e-03,  6.5127e-03,  4.5990e-03,\n",
       "           3.4774e-03,  1.9465e-03,  5.8390e-03,  2.4860e-03,  9.4346e-03,\n",
       "          -1.0706e-03,  4.3090e-03,  7.3015e-03,  3.6435e-03,  3.4028e-03,\n",
       "           8.4882e-03,  8.6748e-03,  4.9223e-03,  3.5874e-03,  5.5096e-03,\n",
       "           7.1100e-03,  7.5835e-03, -3.1286e-03,  6.3781e-03,  4.8540e-03,\n",
       "           1.0469e-02,  8.5899e-03,  1.6353e-03, -1.6734e-03,  9.1114e-03,\n",
       "           1.2786e-02,  5.0217e-03,  2.5739e-03,  7.7898e-03,  1.0050e-02,\n",
       "           5.1784e-03,  5.2335e-03,  6.3731e-03,  2.0514e-03,  5.7889e-03,\n",
       "           3.9761e-03,  2.5567e-03,  6.3074e-03,  7.6442e-03,  6.1295e-03,\n",
       "           7.5837e-03,  5.2002e-03,  8.0240e-03,  6.2454e-03,  7.8378e-03,\n",
       "           3.4707e-03,  8.3433e-03,  5.0025e-03,  1.9727e-03,  7.1243e-03,\n",
       "           6.2856e-03,  1.0338e-02,  8.8676e-03,  5.5094e-03,  4.9278e-03,\n",
       "           1.0471e-02,  1.3247e-02,  4.6599e-03,  9.7483e-03,  3.5811e-03,\n",
       "           5.8336e-03,  6.5733e-03,  7.0248e-03,  4.0611e-03,  3.5264e-03,\n",
       "           8.8520e-03,  9.0361e-03,  4.1524e-03,  1.7397e-03,  3.5142e-03,\n",
       "           3.9566e-03,  5.1961e-03,  4.0803e-03,  5.5159e-03,  5.8252e-03,\n",
       "           1.5405e-03,  3.0995e-03,  6.3046e-03,  6.5770e-03,  7.3602e-03,\n",
       "           5.7983e-03,  5.5526e-03,  5.4903e-03,  1.0781e-03,  6.8159e-03,\n",
       "           3.3604e-03, -2.0734e-03,  3.0668e-03,  7.2486e-03,  1.2638e-03,\n",
       "           9.5113e-03,  6.6294e-03,  7.5373e-03,  5.7109e-03,  6.0891e-03,\n",
       "           8.6012e-03,  4.3219e-03,  1.1136e-02,  1.0371e-02,  1.1113e-02,\n",
       "           8.2570e-03,  2.4907e-03,  8.1721e-03, -2.7443e-04,  5.2411e-03,\n",
       "           1.0268e-03,  2.9819e-03,  8.4168e-03,  1.8556e-03,  1.1335e-02,\n",
       "           6.7586e-03,  1.2441e-04,  4.0875e-03,  1.1302e-02,  6.5480e-03,\n",
       "           5.3294e-03,  3.5891e-03,  5.9123e-03,  3.8286e-03,  8.2786e-03,\n",
       "           8.7284e-03,  8.7259e-03,  7.1924e-03,  1.8909e-03,  4.3217e-03,\n",
       "           6.0273e-03,  2.8571e-03,  7.9638e-03,  1.5981e-03,  8.5816e-03,\n",
       "          -1.3903e-04,  8.9112e-03,  1.1155e-02,  8.8766e-03,  6.8293e-03,\n",
       "           6.9198e-03,  7.0400e-03,  4.3423e-03,  7.7654e-03,  6.2332e-03,\n",
       "           3.7545e-03,  8.0621e-03,  5.0513e-03,  7.1783e-03,  1.9987e-03,\n",
       "           1.0265e-02,  2.7393e-03,  5.4755e-03,  2.9082e-03,  6.1042e-03,\n",
       "           4.4635e-03,  8.2199e-03,  8.4099e-03,  2.5856e-03,  5.9434e-03,\n",
       "           3.2988e-03,  8.1300e-03,  7.3749e-03,  1.7174e-03,  6.3883e-03,\n",
       "           6.7474e-03,  7.0420e-03,  2.4155e-03,  8.8458e-03,  7.8120e-03,\n",
       "           9.4958e-03, -1.7014e-03,  8.7263e-03,  5.5123e-03,  1.3301e-02,\n",
       "           2.8165e-03,  2.6633e-03,  5.2803e-03,  9.7212e-03,  3.3241e-03,\n",
       "           7.3149e-03,  5.8899e-03,  3.4652e-03,  7.8155e-03,  2.2678e-03,\n",
       "           6.1102e-03,  8.6226e-03,  5.4480e-03], device='cuda:0',\n",
       "         requires_grad=True)),\n",
       " ('hidden.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 9.4764e-01, -3.8703e-03, -7.3653e-05,  ..., -2.3917e-04,\n",
       "           -1.9959e-03, -3.5741e-03],\n",
       "          [ 2.6459e-04,  9.5387e-01,  1.2470e-03,  ...,  1.0575e-03,\n",
       "            6.3770e-05,  3.8103e-03],\n",
       "          [ 6.2172e-05,  1.3528e-03,  9.7684e-01,  ...,  4.5278e-04,\n",
       "            2.1854e-03,  4.4185e-03],\n",
       "          ...,\n",
       "          [ 1.8503e-03, -2.3861e-03, -4.9823e-03,  ...,  9.4783e-01,\n",
       "            2.4378e-03,  1.2795e-03],\n",
       "          [-9.3133e-04, -5.3770e-04,  1.8286e-03,  ...,  2.2067e-03,\n",
       "            9.5197e-01, -3.5268e-03],\n",
       "          [ 1.0314e-03,  3.7361e-03,  3.1810e-03,  ..., -1.9908e-03,\n",
       "           -2.2052e-04,  9.5081e-01]], device='cuda:0', requires_grad=True)),\n",
       " ('hidden.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 5.5639e-04,  6.4968e-04, -1.5297e-05,  7.7030e-04,  4.9254e-04,\n",
       "           6.9256e-04,  1.3656e-04, -8.9783e-05,  3.2052e-04, -9.0493e-05,\n",
       "           6.1690e-04,  6.1940e-05,  7.3617e-04,  4.4655e-04,  4.6377e-04,\n",
       "           1.5187e-04,  3.5180e-04,  5.5958e-05,  7.3384e-04,  8.3151e-04,\n",
       "           3.2574e-04, -2.2553e-04,  4.1069e-04,  7.2426e-04,  1.6391e-04,\n",
       "           1.4124e-04,  1.4671e-04, -7.8817e-06,  4.6213e-04,  2.8725e-04,\n",
       "           4.8512e-04, -1.8060e-05,  7.5144e-04,  8.4875e-04,  0.0000e+00,\n",
       "          -5.1432e-05, -2.4961e-06, -5.0365e-05,  4.4215e-04, -2.7132e-04,\n",
       "           2.1830e-04,  3.6274e-04,  9.5691e-04,  4.5633e-05,  4.0061e-04,\n",
       "           6.5040e-04,  2.5489e-04,  2.7830e-04,  2.0078e-04,  2.4105e-04,\n",
       "          -1.6567e-03,  2.8357e-04,  4.8414e-04, -9.2284e-05,  6.4498e-04,\n",
       "           5.1605e-04,  4.4850e-04,  5.7566e-05,  6.8348e-04,  7.1340e-04,\n",
       "           1.1126e-03, -1.3753e-04,  5.2049e-05,  3.8378e-04,  8.2640e-04,\n",
       "           8.2816e-04,  6.3154e-04, -5.7217e-06, -8.3091e-07,  6.7165e-04,\n",
       "           5.3242e-04,  6.1795e-04,  4.6131e-04, -4.3564e-05,  6.0108e-04,\n",
       "           3.7316e-04,  3.8606e-04,  7.4297e-04,  2.1306e-04,  1.4874e-04,\n",
       "           1.8910e-04,  4.9192e-04,  6.4519e-04,  8.8156e-04,  4.4274e-04,\n",
       "           4.1041e-04,  3.7368e-04,  5.2532e-04,  3.8715e-04,  1.0573e-03,\n",
       "           2.8746e-04, -3.3218e-04,  6.6834e-04,  7.9979e-04,  7.1233e-04,\n",
       "           6.0453e-04, -3.7849e-04,  3.2070e-04,  8.5596e-05, -7.5956e-06,\n",
       "          -6.4899e-05, -5.2711e-04,  4.8833e-04,  5.6738e-04,  8.2876e-04,\n",
       "           2.9926e-04,  5.9620e-04,  6.9135e-04,  2.6931e-04,  7.8441e-05,\n",
       "           3.6989e-04, -4.6839e-04,  4.6552e-04,  6.1899e-04,  9.4441e-04,\n",
       "           3.1397e-04,  6.6837e-04,  4.0712e-04,  6.9790e-04, -1.3145e-04,\n",
       "           6.3861e-05,  4.7900e-04,  5.9698e-04,  8.8325e-06,  4.8264e-04,\n",
       "           4.1405e-04,  2.4049e-04,  2.4904e-04,  2.3682e-04,  4.2871e-04,\n",
       "           2.1687e-04,  2.0415e-04,  2.5135e-04,  9.2369e-04,  2.9252e-04,\n",
       "          -7.2185e-05,  1.7181e-04,  4.6994e-04,  3.5957e-04,  2.3171e-04,\n",
       "          -1.8560e-04, -1.5271e-04,  1.0458e-04,  1.9621e-04,  5.8314e-04,\n",
       "           5.8573e-04,  6.6939e-04,  6.4499e-04,  1.1764e-04,  7.2788e-04,\n",
       "           4.0377e-04,  3.7181e-04,  6.3738e-04, -1.3883e-03, -2.5504e-05,\n",
       "           7.1862e-04, -1.2870e-04,  2.8599e-04,  1.4491e-04,  5.9481e-04,\n",
       "           9.6895e-04,  5.4105e-04,  6.3827e-04,  9.0916e-05,  3.2791e-04,\n",
       "           4.1005e-04,  4.8228e-04,  4.5853e-04,  2.3380e-04,  3.3319e-04,\n",
       "           2.0247e-04, -5.6805e-05,  5.8189e-05,  6.7157e-04,  2.6161e-04,\n",
       "           3.5685e-04,  4.7303e-04,  1.0611e-03,  8.7062e-04,  7.7179e-04,\n",
       "           4.0253e-04,  1.2206e-03, -9.8148e-05,  7.5685e-04,  7.2515e-04,\n",
       "           1.7037e-04,  1.9405e-04,  4.9301e-04,  1.3997e-04, -2.7491e-04,\n",
       "           5.7951e-04,  6.8681e-04,  6.3491e-04,  4.4985e-05,  4.5374e-04,\n",
       "           9.3921e-04, -5.5411e-05,  4.8858e-04, -3.3834e-04,  7.6782e-04,\n",
       "           5.5189e-04,  3.9960e-04,  9.4117e-04,  8.3542e-04,  4.7974e-05,\n",
       "           2.0536e-04,  5.3173e-04,  5.0675e-04,  5.5134e-04,  1.9009e-04,\n",
       "           1.0688e-03,  2.2675e-04,  5.0263e-04, -3.5117e-05, -2.9560e-05,\n",
       "           3.7478e-04, -1.2304e-03, -8.5849e-05,  5.1283e-04,  6.5178e-04,\n",
       "           4.4572e-04,  5.7166e-04,  4.8282e-04,  2.5271e-04,  4.3055e-04,\n",
       "           5.8942e-04,  3.3288e-04,  7.6585e-04,  4.4961e-05,  1.7481e-05,\n",
       "           5.2518e-04,  5.3163e-04, -2.6481e-04,  5.1042e-04,  7.0584e-04,\n",
       "           4.4614e-04,  4.8793e-05,  7.0352e-04,  4.2071e-04,  4.7666e-04,\n",
       "           2.1224e-05,  5.8968e-04,  3.9049e-04,  1.9578e-05,  5.6135e-04,\n",
       "          -1.5231e-04, -1.6032e-04,  9.8103e-04,  3.0338e-04,  5.9556e-04,\n",
       "           2.6253e-04,  1.1138e-04,  2.8439e-04,  7.0084e-04, -1.7328e-05,\n",
       "           7.6117e-05,  2.9120e-04,  1.0896e-03,  4.9069e-04,  3.7002e-04,\n",
       "           7.3931e-04, -1.9469e-05, -5.4505e-05,  1.1369e-03,  2.8173e-04,\n",
       "           6.1493e-04,  1.8502e-04,  1.2246e-05,  8.8107e-04, -1.8898e-04,\n",
       "           5.4006e-04,  4.3940e-04,  6.2512e-04,  1.7090e-04,  6.0779e-04,\n",
       "           8.8073e-04,  6.0834e-04, -3.2614e-04, -1.6136e-06,  9.0137e-04,\n",
       "           1.3262e-03,  5.1779e-04,  5.3277e-04,  3.5739e-04,  5.6370e-04,\n",
       "           1.2003e-04,  2.6626e-04,  1.4166e-04,  3.8161e-04,  2.4210e-04,\n",
       "           3.6172e-04,  3.2845e-04, -4.0298e-04,  2.8779e-04,  1.0982e-03,\n",
       "           1.5778e-05,  4.8634e-04,  6.0243e-04,  3.0479e-04,  2.1681e-04,\n",
       "           5.5038e-04,  3.9672e-04,  2.1771e-04, -1.5925e-03,  4.2375e-04,\n",
       "           4.2675e-04,  5.5431e-04,  4.1944e-04,  4.8505e-04,  4.5894e-04,\n",
       "           9.6008e-04, -7.5902e-05,  5.8790e-05,  8.2217e-04, -1.5055e-04,\n",
       "           9.0970e-04,  3.3354e-04,  6.8250e-04, -4.2482e-05,  6.8420e-04,\n",
       "           2.5909e-04,  5.9087e-04,  3.9318e-04,  2.6758e-04,  5.2042e-04,\n",
       "           6.8082e-04,  2.6421e-04,  2.7578e-04,  3.7302e-04, -5.1790e-05,\n",
       "           3.1587e-04,  7.2830e-07,  3.8466e-04,  5.4657e-04,  4.6701e-04,\n",
       "           5.3356e-04,  4.0490e-04,  3.2360e-04,  3.8937e-04,  5.4249e-04,\n",
       "           5.9491e-04,  5.0622e-04,  6.6655e-04,  1.8664e-04,  7.6067e-04,\n",
       "           5.0705e-04,  3.2810e-04,  1.6231e-04,  3.8022e-04,  4.7117e-04,\n",
       "           5.9844e-04,  5.7682e-04, -1.0968e-04,  9.7591e-05,  1.1077e-03,\n",
       "           3.8970e-04, -1.1393e-04,  7.9991e-04,  9.3237e-04,  8.6259e-04,\n",
       "           4.3483e-04,  4.0727e-04,  1.7443e-04,  6.5189e-04,  7.0263e-04,\n",
       "           5.2325e-05,  6.2115e-04, -1.3301e-04, -3.0111e-04,  5.8154e-04,\n",
       "           4.1856e-04, -2.0225e-05,  2.1072e-04,  6.8347e-04,  5.7018e-04,\n",
       "           4.2768e-04,  3.9466e-04,  9.1285e-05,  3.4448e-04,  3.5437e-04,\n",
       "           4.3282e-04,  2.3749e-04,  9.7202e-04, -9.2967e-05,  5.8823e-04,\n",
       "           9.1762e-04,  4.9324e-04,  3.5763e-04,  9.5943e-04,  9.5287e-04,\n",
       "           6.1705e-04,  3.1127e-04,  1.1888e-04,  1.0015e-03,  1.0037e-03,\n",
       "           1.3472e-04,  4.6860e-04,  4.6347e-04,  5.6069e-04,  2.2008e-04,\n",
       "           1.0711e-03, -2.4373e-04,  5.2055e-04, -5.6484e-04,  2.4928e-04,\n",
       "           2.4173e-04,  3.0654e-05, -3.7853e-04,  6.5450e-04,  1.5022e-04,\n",
       "           2.7133e-04,  5.6375e-05,  2.5613e-04, -1.2516e-04, -6.3897e-05,\n",
       "           9.3419e-04,  2.8715e-04,  1.2812e-04,  1.6132e-04,  5.4891e-04,\n",
       "           3.6031e-04, -1.1689e-05,  4.6230e-04,  5.4149e-04, -2.1569e-04,\n",
       "           3.3590e-04,  2.2027e-04,  6.9239e-04,  6.2214e-04,  8.7864e-05,\n",
       "           4.2742e-04,  4.9108e-04,  4.7184e-04,  4.5090e-04,  2.6262e-04,\n",
       "           2.4934e-04,  2.0000e-04,  3.6541e-04,  3.0549e-04,  2.4829e-04,\n",
       "           3.0087e-04,  8.8100e-04,  5.1260e-04,  4.7749e-04,  1.1157e-03,\n",
       "           3.2996e-04,  1.7660e-05,  1.3407e-04,  1.2081e-04,  4.7773e-04,\n",
       "          -7.3404e-05, -2.7155e-05,  4.9529e-05,  1.0528e-03,  6.3486e-04,\n",
       "           4.0480e-04,  4.7633e-04, -4.8247e-05,  4.9209e-04,  4.8849e-04,\n",
       "           5.2130e-04,  1.8538e-03, -4.6649e-05, -1.8153e-04, -1.3351e-04,\n",
       "           3.2963e-04,  7.2943e-04,  7.6657e-04, -1.2576e-04,  7.9958e-04,\n",
       "           1.7448e-04, -1.1228e-04,  2.7175e-04,  9.3695e-04,  3.8305e-04,\n",
       "          -2.0577e-05,  6.2357e-04,  1.0889e-04, -4.8019e-05,  2.6430e-04,\n",
       "           6.6449e-04,  6.8539e-04,  2.2217e-04,  6.1115e-04, -1.4693e-03,\n",
       "           5.7063e-05,  7.3042e-04,  3.4920e-04,  8.9771e-04,  2.5497e-04,\n",
       "           8.6390e-04,  4.2661e-04,  1.3787e-05,  4.6950e-04, -1.6975e-04,\n",
       "           2.3392e-04,  5.5807e-04,  1.2218e-03,  2.6376e-04,  4.7263e-04,\n",
       "           3.9493e-04,  6.0290e-04, -1.1144e-04,  5.4792e-05,  5.5148e-04,\n",
       "           4.2266e-04, -6.2652e-05,  3.5811e-04,  6.3423e-04,  6.4876e-04,\n",
       "           6.3725e-04,  1.3534e-04,  8.4465e-04,  2.7720e-04, -1.1820e-05,\n",
       "           5.6310e-04,  4.1195e-04,  1.0438e-04, -2.0759e-05,  5.6062e-04,\n",
       "           3.7598e-04, -1.5004e-03,  4.0319e-04,  2.1187e-04,  5.6442e-04,\n",
       "           1.3950e-04,  4.6793e-04,  2.7276e-04, -1.8989e-04,  1.3617e-04,\n",
       "           1.6428e-04,  5.0022e-04,  7.1459e-04,  2.3861e-04,  1.4175e-04,\n",
       "           1.1773e-03,  2.0199e-04,  7.6468e-04, -1.5344e-05,  9.3102e-04,\n",
       "           1.4309e-03,  5.6826e-04,  3.2398e-04,  4.1221e-04,  2.1481e-05,\n",
       "           7.6896e-04,  4.9371e-04,  7.1970e-04, -4.7331e-06,  8.1601e-04,\n",
       "           3.5157e-04,  5.8010e-04,  6.7491e-05,  4.8612e-04,  8.7933e-04,\n",
       "          -3.1212e-04,  3.6677e-04,  1.3956e-04,  1.2853e-03,  5.2832e-04,\n",
       "           6.1911e-04,  2.1326e-04,  4.1840e-04, -1.4157e-03,  7.7429e-04,\n",
       "           6.4435e-04, -1.1288e-03,  7.2735e-04,  5.9644e-04,  3.1885e-04,\n",
       "           3.3895e-04,  2.0636e-04,  3.6600e-04,  9.7862e-04, -1.8727e-04,\n",
       "           1.6657e-04,  5.0745e-04, -2.0323e-04,  6.1153e-04,  1.7347e-05,\n",
       "           3.9112e-04, -3.1378e-05,  1.2373e-04,  5.1969e-06,  6.6236e-04,\n",
       "           3.2519e-04,  3.2112e-04,  7.0915e-04,  4.5918e-04,  1.3197e-05,\n",
       "           1.8136e-04,  6.0226e-04,  3.4276e-04,  1.2228e-04,  7.7221e-04,\n",
       "           1.1213e-03,  4.2446e-04,  1.0780e-04,  1.9234e-04,  6.4327e-04,\n",
       "           7.0054e-04,  1.0241e-03, -1.3858e-03,  7.6261e-04,  1.1733e-03,\n",
       "           4.7436e-04,  5.0717e-04, -2.6830e-04,  8.4329e-04,  5.4530e-04,\n",
       "           8.9327e-04, -1.3685e-04, -3.1816e-05,  1.5159e-04,  4.0719e-04,\n",
       "           8.4115e-04,  4.1571e-04,  8.1349e-04,  2.1549e-04,  7.2034e-04,\n",
       "           3.0750e-04, -1.6336e-04, -2.6946e-05,  5.0369e-04,  3.4221e-04,\n",
       "           3.9328e-04,  9.4352e-04,  8.4859e-04,  2.5558e-04,  8.6039e-05,\n",
       "           2.6717e-04,  2.9867e-04,  1.3897e-04, -1.8898e-04,  1.2226e-04,\n",
       "          -6.7254e-05,  3.2811e-04,  9.2029e-04,  1.0503e-04,  4.5970e-04,\n",
       "           1.0528e-03,  3.5495e-04,  4.9975e-04,  5.2477e-04,  1.0327e-04,\n",
       "           1.0569e-03, -1.1195e-04,  4.0792e-04,  8.2906e-04,  4.2077e-04,\n",
       "           5.5026e-04,  5.1568e-04,  8.6055e-04,  3.3642e-04,  7.1105e-05,\n",
       "           1.7019e-04,  3.0528e-04,  1.0904e-03,  4.8264e-04,  6.8805e-04,\n",
       "           3.4981e-04,  9.9556e-04,  1.3904e-05,  1.0420e-03,  9.0494e-04,\n",
       "           3.8466e-04,  9.4123e-04,  4.4227e-04,  1.3894e-04,  3.3217e-04,\n",
       "           4.8127e-04, -1.7599e-03, -2.3168e-04,  6.3642e-04, -2.0125e-04,\n",
       "           7.1771e-04,  2.3081e-04,  6.2541e-04,  8.2008e-04,  5.7414e-04,\n",
       "           5.2958e-04,  4.2866e-04,  4.8865e-04,  5.2962e-04,  6.5705e-04,\n",
       "           9.5739e-05,  1.1418e-04,  3.8637e-04, -9.8695e-04,  4.1370e-04,\n",
       "          -2.4917e-04,  8.8698e-05,  5.5744e-04, -8.7837e-05,  4.9418e-04,\n",
       "           5.2258e-04, -3.8761e-04,  2.8112e-05,  7.6107e-04,  5.0627e-04,\n",
       "           2.6890e-04, -1.1721e-04,  6.8798e-04,  3.9111e-05,  4.6219e-04,\n",
       "           4.2042e-04,  1.1132e-03,  9.6595e-04, -1.3093e-04,  3.5328e-04,\n",
       "           2.7268e-04, -1.0046e-05,  5.8404e-04,  2.6524e-04,  2.0516e-04,\n",
       "          -6.7653e-04,  8.0327e-04,  1.1307e-03,  8.6582e-04,  6.3461e-04,\n",
       "           5.6145e-04,  5.1484e-04,  2.7577e-04,  7.8376e-04,  1.1938e-03,\n",
       "           1.1801e-03,  7.7113e-04,  4.3187e-04,  6.3327e-04, -2.1143e-04,\n",
       "           4.4598e-04,  5.6993e-04,  1.2668e-04, -9.0451e-05,  9.8208e-05,\n",
       "           2.4437e-04,  1.0248e-04,  3.2967e-04, -4.2535e-04,  8.8529e-05,\n",
       "           6.4340e-04,  6.5717e-04,  4.4599e-04,  8.0567e-05,  1.7574e-04,\n",
       "           4.1623e-04,  8.1459e-04,  3.3633e-04,  7.1823e-04,  5.2831e-04,\n",
       "           7.6166e-04,  3.0948e-04,  3.6551e-04,  1.0370e-03,  4.8254e-04,\n",
       "          -1.1181e-04,  1.6217e-03,  1.4005e-04,  7.8892e-04,  8.7317e-05,\n",
       "           4.6774e-04,  5.9404e-04,  4.0953e-05,  6.7312e-05,  1.1660e-04,\n",
       "           6.6163e-04,  4.4727e-04,  4.6465e-04], device='cuda:0',\n",
       "         requires_grad=True)),\n",
       " ('hidden2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 9.5281e-01, -3.5718e-03,  2.3453e-03,  ..., -2.1853e-04,\n",
       "           -1.4031e-03, -3.6959e-03],\n",
       "          [ 3.4804e-04,  9.5831e-01, -2.4634e-03,  ...,  1.5816e-03,\n",
       "            1.0339e-05,  4.3044e-03],\n",
       "          [ 1.2576e-03,  1.2611e-03,  9.8312e-01,  ...,  7.0269e-04,\n",
       "            5.5959e-04,  3.1011e-03],\n",
       "          ...,\n",
       "          [ 1.6023e-03, -2.5567e-03, -4.0807e-03,  ...,  9.5209e-01,\n",
       "            2.1762e-03,  1.1298e-03],\n",
       "          [-4.4565e-04, -4.9710e-04,  7.8875e-04,  ...,  2.3379e-03,\n",
       "            9.5571e-01, -3.3696e-03],\n",
       "          [ 5.8425e-04,  4.0147e-03,  2.1358e-03,  ..., -9.1147e-04,\n",
       "           -4.8624e-04,  9.5719e-01]], device='cuda:0', requires_grad=True)),\n",
       " ('hidden2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 6.2823e-04,  7.3956e-04, -3.5617e-05,  7.2100e-04,  5.2155e-04,\n",
       "           6.2022e-04,  3.5747e-04, -6.0924e-05,  4.8267e-04,  5.2766e-04,\n",
       "           6.7142e-04,  1.2586e-04,  8.3403e-04,  5.4960e-04,  4.6265e-04,\n",
       "           1.9204e-04,  3.9637e-04,  8.9107e-04,  6.7745e-04,  8.4556e-04,\n",
       "           2.4728e-04, -1.4749e-04,  3.6281e-04,  9.0674e-04,  1.5893e-04,\n",
       "           8.2155e-05,  1.7219e-04, -4.3137e-06,  4.3263e-04,  3.1937e-04,\n",
       "           5.4298e-04,  9.2672e-06,  7.5129e-04,  9.5614e-04,  0.0000e+00,\n",
       "          -1.1773e-04,  7.1918e-04,  2.2921e-04,  3.5829e-04, -2.3192e-04,\n",
       "           1.3465e-04,  4.0989e-04,  9.5104e-04, -2.2529e-05,  4.3702e-04,\n",
       "           5.9684e-04,  3.1894e-04,  2.7793e-04,  3.2259e-04,  3.6271e-04,\n",
       "          -7.5160e-04,  3.1670e-04,  4.8368e-04,  6.3162e-06,  6.3809e-04,\n",
       "           5.9059e-04,  4.2290e-04,  3.1977e-04,  8.7249e-04,  6.8426e-04,\n",
       "           1.3403e-03, -7.7590e-05,  1.0786e-04,  3.9907e-04,  9.0118e-04,\n",
       "           7.6155e-04,  7.5863e-04, -9.0876e-05,  1.4093e-04,  8.6958e-04,\n",
       "           5.9631e-04,  6.7023e-04,  6.4065e-04,  6.3957e-05,  6.6156e-04,\n",
       "           3.7412e-04,  5.3830e-04,  7.9991e-04,  2.5835e-04,  6.8721e-04,\n",
       "           1.3496e-04,  4.9304e-04,  6.1081e-04,  8.7133e-04,  4.0242e-04,\n",
       "           4.0142e-04,  3.0900e-04,  9.6065e-04,  5.4559e-04,  1.0259e-03,\n",
       "           7.0622e-04, -3.5146e-04,  6.9269e-04,  8.0717e-04,  7.2699e-04,\n",
       "           5.1243e-04, -4.2079e-04,  7.1437e-04,  1.6439e-04,  2.0832e-04,\n",
       "           2.5789e-05, -4.9168e-04,  4.8066e-04,  7.5296e-04,  8.3166e-04,\n",
       "           3.0939e-04,  7.5431e-04,  6.7206e-04,  2.1981e-04,  1.2887e-04,\n",
       "           4.0678e-04, -4.5457e-04,  5.5433e-04,  6.3618e-04,  8.7864e-04,\n",
       "           4.3707e-04,  6.2045e-04,  4.1331e-04,  5.8395e-04, -1.0701e-04,\n",
       "           2.6973e-05,  5.4341e-04,  6.2645e-04,  3.6484e-05,  7.0256e-04,\n",
       "           4.5995e-04,  2.8988e-04,  3.0837e-04,  2.9561e-04,  3.5524e-04,\n",
       "           2.1223e-04,  2.7928e-04,  1.2606e-04,  8.3719e-04,  1.8814e-04,\n",
       "          -2.0272e-05,  3.6795e-04,  5.0552e-04,  3.5499e-04,  2.0708e-04,\n",
       "           6.7363e-04, -1.7997e-04,  5.2004e-04,  3.9538e-04,  5.1960e-04,\n",
       "           5.9453e-04,  7.6207e-04,  6.8730e-04,  3.3262e-05,  9.9782e-04,\n",
       "           4.5131e-04,  3.9799e-04,  5.9758e-04, -4.7822e-04,  8.2752e-06,\n",
       "           6.8355e-04, -1.6734e-04,  4.1817e-04,  2.9732e-04,  6.8389e-04,\n",
       "           1.2759e-03,  6.9729e-04,  6.6475e-04,  1.2910e-04,  2.2746e-04,\n",
       "           5.5997e-04,  4.1547e-04,  4.5996e-04,  1.5607e-04,  2.8538e-04,\n",
       "           3.1356e-04,  1.5012e-04,  1.1034e-04,  6.2782e-04,  2.4844e-04,\n",
       "           3.6988e-04,  5.3919e-04,  9.6655e-04,  8.4804e-04,  8.6217e-04,\n",
       "           4.2671e-04,  1.2994e-03,  1.8391e-05,  7.1362e-04,  7.3031e-04,\n",
       "           2.9832e-04,  1.8694e-04,  4.9462e-04,  1.9268e-04, -2.8945e-05,\n",
       "           5.5143e-04,  7.0264e-04,  5.6722e-04,  1.2440e-04,  5.8669e-04,\n",
       "           9.6495e-04,  4.1935e-04,  4.5461e-04, -2.8468e-04,  8.6005e-04,\n",
       "           5.2822e-04,  4.2692e-04,  1.0245e-03,  8.6893e-04,  9.0828e-05,\n",
       "           2.8674e-04,  5.2290e-04,  4.8800e-04,  4.6203e-04,  4.4015e-04,\n",
       "           1.1113e-03,  2.3470e-04,  4.4020e-04,  7.4307e-05,  2.2776e-05,\n",
       "           3.2177e-04, -6.8736e-04,  2.8142e-04,  4.8494e-04,  8.2047e-04,\n",
       "           4.5057e-04,  5.2877e-04,  4.3814e-04,  3.2177e-04,  4.7151e-04,\n",
       "           5.7636e-04,  4.0687e-04,  7.9832e-04, -7.1016e-05,  1.9282e-04,\n",
       "           5.8175e-04,  5.6489e-04,  2.3110e-04,  6.4475e-04,  7.1209e-04,\n",
       "           4.8712e-04,  2.0819e-04,  9.3192e-04,  5.4340e-04,  4.1965e-04,\n",
       "           2.8665e-04,  6.2905e-04,  4.9385e-04,  1.6311e-04,  6.0677e-04,\n",
       "          -1.4318e-04, -1.8886e-04,  1.0320e-03,  3.0592e-04,  6.7420e-04,\n",
       "           2.7884e-04,  2.9605e-04,  4.1022e-04,  6.7403e-04,  2.3287e-04,\n",
       "           5.0845e-05,  3.2540e-04,  1.0846e-03,  5.2371e-04,  4.1931e-04,\n",
       "           8.5872e-04,  4.1760e-05, -8.1271e-05,  1.2590e-03,  3.5178e-04,\n",
       "           6.1565e-04,  1.7666e-04,  7.4631e-05,  9.9667e-04,  3.6396e-04,\n",
       "           5.7062e-04,  6.3131e-04,  6.3040e-04,  1.7709e-04,  8.1911e-04,\n",
       "           9.3282e-04,  5.8339e-04, -2.3180e-04, -1.5634e-05,  9.7923e-04,\n",
       "           1.2209e-03,  5.0409e-04,  6.2482e-04,  4.0892e-04,  7.2890e-04,\n",
       "           1.2168e-04,  2.4411e-04,  6.9109e-05,  4.1234e-04,  2.0446e-04,\n",
       "           3.9000e-04,  3.5962e-04, -4.1324e-04,  3.4216e-04,  1.0958e-03,\n",
       "           9.6181e-06,  4.9141e-04,  1.2349e-03,  4.2895e-04,  3.0792e-04,\n",
       "           3.8534e-04,  4.3795e-04,  2.4152e-04, -5.3378e-04,  4.1204e-04,\n",
       "           3.4903e-04,  6.4669e-04,  3.9159e-04,  5.9181e-04,  3.7070e-04,\n",
       "           8.6772e-04, -8.7046e-05, -3.8791e-05,  7.8360e-04, -1.3741e-04,\n",
       "           1.1853e-03,  2.6808e-04,  7.3832e-04, -1.2443e-04,  6.2377e-04,\n",
       "           2.8113e-04,  5.4394e-04,  3.8014e-04,  3.1517e-04,  3.9583e-04,\n",
       "           6.9322e-04,  2.0203e-04,  1.6317e-04,  4.0934e-04, -8.3529e-05,\n",
       "           5.6989e-04,  7.8310e-05,  2.7415e-04,  6.7974e-04,  4.1662e-04,\n",
       "           5.7107e-04,  3.0112e-04,  2.8848e-04,  4.5096e-04,  6.1710e-04,\n",
       "           7.0238e-04,  5.2325e-04,  6.5757e-04,  2.5043e-04,  7.9583e-04,\n",
       "           3.9191e-04,  3.0771e-04,  1.8161e-04,  4.3496e-04,  5.3483e-04,\n",
       "           5.8037e-04,  6.5927e-04,  3.1392e-04,  6.8908e-05,  9.3577e-04,\n",
       "           3.9066e-04,  2.6934e-04,  7.9375e-04,  1.1708e-03,  8.7994e-04,\n",
       "           5.2669e-04,  3.7380e-04,  7.0128e-04,  5.9135e-04,  6.9346e-04,\n",
       "           2.5836e-05,  6.8642e-04,  2.0089e-04, -2.8377e-04,  5.5241e-04,\n",
       "           4.4272e-04,  3.4249e-05,  2.9066e-04,  8.8408e-04,  6.0749e-04,\n",
       "           4.7503e-04,  5.6388e-04,  6.0472e-05,  3.0720e-04,  3.4771e-04,\n",
       "           4.1065e-04,  2.8240e-04,  9.9898e-04, -2.3770e-04,  6.2229e-04,\n",
       "           1.0189e-03,  6.5073e-04,  4.0891e-04,  1.0296e-03,  1.1115e-03,\n",
       "           6.5594e-04,  3.2543e-04,  1.3917e-04,  1.0779e-03,  1.3753e-03,\n",
       "           1.1593e-04,  5.1688e-04,  4.8380e-04,  5.1181e-04,  6.9503e-04,\n",
       "           1.0422e-03, -1.9375e-04,  5.1701e-04, -5.4103e-04,  2.9497e-04,\n",
       "           2.1697e-04,  1.2730e-05, -5.6675e-04,  5.9137e-04,  1.1311e-04,\n",
       "           3.0364e-04,  1.2796e-04,  2.7892e-04,  1.0013e-04,  1.8865e-04,\n",
       "           8.0184e-04,  2.1592e-04,  1.8296e-04,  9.3254e-05,  5.0567e-04,\n",
       "           3.7710e-04, -8.6724e-05,  5.1923e-04,  5.5982e-04,  5.9652e-05,\n",
       "           3.4917e-04,  3.0778e-04,  7.1363e-04,  7.3330e-04,  2.0453e-04,\n",
       "           4.3174e-04,  5.6060e-04,  4.3289e-04,  5.5602e-04,  3.4358e-04,\n",
       "           2.7040e-04,  3.1166e-04,  4.7572e-04,  4.2488e-04,  4.9027e-04,\n",
       "           2.2770e-04,  1.1167e-03,  7.1666e-04,  5.3621e-04,  1.2375e-03,\n",
       "           2.5779e-04,  2.2947e-04,  1.1591e-04,  1.2266e-04,  5.3439e-04,\n",
       "           2.1134e-06,  5.3118e-05, -2.9923e-05,  1.1552e-03,  6.4510e-04,\n",
       "           2.5083e-04,  4.3844e-04,  4.6701e-04,  5.6909e-04,  5.2472e-04,\n",
       "           7.1118e-04,  3.4429e-03, -3.1442e-05, -2.6560e-04, -9.5990e-05,\n",
       "           2.3497e-04,  7.2077e-04,  6.9713e-04,  3.8902e-04,  6.6456e-04,\n",
       "           1.8523e-04, -2.1436e-04,  1.2666e-04,  1.0654e-03,  4.0290e-04,\n",
       "          -1.8684e-04,  6.2237e-04,  1.2833e-04, -5.0969e-05,  4.4216e-04,\n",
       "           6.7022e-04,  6.1639e-04,  2.6317e-04,  5.9713e-04, -8.1950e-04,\n",
       "           7.3301e-05,  9.7343e-04,  2.5660e-04,  9.9966e-04,  2.6838e-04,\n",
       "           9.0592e-04,  3.5865e-04,  2.4314e-05,  3.9552e-04, -3.2427e-05,\n",
       "           2.5088e-04,  5.6989e-04,  1.1991e-03,  2.4619e-04,  5.0254e-04,\n",
       "           5.2188e-04,  6.0247e-04,  3.0523e-05,  3.3685e-04,  4.5840e-04,\n",
       "           5.1303e-04,  8.5489e-05,  4.8964e-04,  5.8346e-04,  5.1473e-04,\n",
       "           8.0387e-04,  1.5096e-04,  8.8941e-04,  2.8495e-04, -5.5771e-05,\n",
       "           6.8062e-04,  4.3900e-04,  1.1811e-04,  3.5693e-04,  6.3254e-04,\n",
       "           4.5887e-04, -9.3722e-04,  5.7574e-04,  4.9657e-04,  5.8829e-04,\n",
       "           1.0325e-04,  3.9510e-04,  2.0446e-04, -1.3082e-04,  5.6629e-04,\n",
       "           2.1737e-04,  6.5116e-04,  7.2379e-04,  1.5886e-04,  1.0116e-04,\n",
       "           1.2704e-03,  2.0152e-04,  7.0728e-04,  4.5363e-05,  9.2915e-04,\n",
       "           1.2086e-03,  5.9180e-04,  3.4370e-04,  5.2523e-04,  4.8402e-05,\n",
       "           6.0585e-04,  4.2002e-04,  7.2642e-04, -4.4699e-05,  7.4069e-04,\n",
       "           5.7845e-04,  5.8642e-04,  2.0685e-04,  6.0391e-04,  7.3609e-04,\n",
       "          -3.1213e-04,  5.2003e-04,  1.3771e-04,  1.2857e-03,  5.2922e-04,\n",
       "           5.7233e-04,  2.0079e-04,  5.6885e-04, -1.5169e-03,  7.7706e-04,\n",
       "           7.2246e-04, -1.0169e-03,  6.9396e-04,  2.2009e-03,  5.7127e-04,\n",
       "           2.4755e-04,  2.3202e-04,  4.7047e-04,  1.0943e-03, -4.2631e-04,\n",
       "           2.7456e-04,  5.7031e-04,  1.8012e-05,  7.0314e-04,  2.0950e-04,\n",
       "           4.5337e-04, -1.0730e-04,  2.2367e-04,  1.2480e-04,  8.2024e-04,\n",
       "           4.4656e-04,  3.8291e-04,  6.4308e-04,  3.8511e-04,  4.1519e-05,\n",
       "           7.3082e-04,  7.1733e-04,  3.6002e-04,  2.2640e-04,  8.4582e-04,\n",
       "           1.0485e-03,  3.9591e-04,  1.8131e-04,  2.6859e-04,  6.2197e-04,\n",
       "           6.1337e-04,  1.0788e-03, -5.8592e-04,  6.9558e-04,  1.1889e-03,\n",
       "           5.1629e-04,  4.6534e-04, -3.1119e-04,  1.3485e-03,  5.7086e-04,\n",
       "           9.3070e-04, -9.5157e-05, -1.0604e-04,  2.3221e-04,  3.6234e-04,\n",
       "           8.0517e-04,  5.2259e-04,  7.3260e-04,  2.5214e-04,  8.3698e-04,\n",
       "           3.9690e-04, -1.1379e-04,  1.2624e-06,  5.0373e-04,  4.0039e-04,\n",
       "           4.2554e-04,  9.4654e-04,  9.3567e-04,  3.7349e-04,  3.4520e-04,\n",
       "           3.0053e-04,  3.9223e-04,  2.0655e-04, -1.2159e-04,  1.5898e-04,\n",
       "          -4.0416e-05,  4.6290e-04,  9.1567e-04,  1.6921e-04,  5.8812e-04,\n",
       "           1.0407e-03,  3.2056e-04,  3.5612e-04,  4.4014e-04,  1.4343e-04,\n",
       "           1.2309e-03, -3.5254e-05,  4.4992e-04,  9.1316e-04,  5.0473e-04,\n",
       "           5.4854e-04,  4.9113e-04,  9.5484e-04,  4.9564e-04, -1.1158e-04,\n",
       "           2.3264e-04,  4.9191e-04,  1.2595e-03,  5.0077e-04,  8.3164e-04,\n",
       "           6.0839e-04,  9.6907e-04, -9.8218e-06,  1.0979e-03,  9.7758e-04,\n",
       "           3.5558e-04,  8.8251e-04,  4.9249e-04,  2.8657e-04,  3.7617e-04,\n",
       "           4.8380e-04, -1.0097e-03, -1.9499e-05,  8.0032e-04,  4.2170e-05,\n",
       "           7.5438e-04,  2.6067e-04,  5.4543e-04,  8.9956e-04,  5.6406e-04,\n",
       "           4.1002e-04,  5.4324e-04,  3.8035e-04,  5.4818e-04,  7.2314e-04,\n",
       "           1.6550e-04, -6.2923e-05,  3.7418e-04, -4.2630e-04,  4.2226e-04,\n",
       "          -2.3480e-04,  6.2635e-04,  6.3549e-04,  6.3061e-05,  4.6403e-04,\n",
       "           5.5865e-04, -3.5052e-04,  1.5218e-04,  7.5210e-04,  4.8179e-04,\n",
       "           2.2271e-04, -1.1831e-04,  6.5240e-04,  3.4815e-04,  3.8805e-04,\n",
       "           3.8082e-04,  1.1725e-03,  8.6477e-04, -5.9634e-05,  6.1037e-04,\n",
       "           3.5339e-04,  5.8374e-05,  5.8784e-04,  3.8905e-04,  2.1913e-04,\n",
       "          -1.3415e-03,  7.2652e-04,  1.1646e-03,  8.7423e-04,  6.8461e-04,\n",
       "           6.3373e-04,  5.3566e-04,  5.4699e-04,  7.0853e-04,  1.1244e-03,\n",
       "           1.2586e-03,  8.6807e-04,  4.1749e-04,  6.9542e-04, -1.5493e-04,\n",
       "           3.5948e-04,  6.4144e-04,  5.1295e-04, -9.4697e-05,  1.7330e-04,\n",
       "           3.1788e-04,  1.8621e-04,  1.9764e-04, -1.7667e-04,  5.4674e-05,\n",
       "           6.4164e-04,  7.3936e-04,  5.4827e-04,  7.2386e-04,  3.0001e-04,\n",
       "           3.9930e-04,  7.6514e-04,  6.5795e-04,  7.1423e-04,  5.1296e-04,\n",
       "           8.5444e-04,  5.0324e-04,  3.5731e-04,  1.0247e-03,  3.7126e-04,\n",
       "          -1.8299e-04,  2.0179e-03,  1.3455e-04,  7.5848e-04,  4.3863e-04,\n",
       "           4.2915e-04,  7.3432e-04, -4.9773e-05,  1.1100e-04,  2.0014e-04,\n",
       "           5.9523e-04,  4.9944e-04,  3.9763e-04], device='cuda:0',\n",
       "         requires_grad=True)),\n",
       " ('output.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 9.5759e-01, -5.8581e-03,  1.2347e-03,  ..., -1.2126e-03,\n",
       "           -1.8541e-03, -5.6737e-03],\n",
       "          [-4.9667e-03,  9.6289e-01, -9.3602e-03,  ..., -6.9046e-04,\n",
       "           -4.1447e-03,  1.8920e-03],\n",
       "          [ 8.3459e-05, -1.7740e-04,  9.8783e-01,  ..., -2.5027e-04,\n",
       "           -1.7298e-03,  1.0436e-03],\n",
       "          ...,\n",
       "          [ 5.6425e-04, -5.1997e-03, -4.0934e-03,  ...,  9.5646e-01,\n",
       "            5.4871e-04, -1.1452e-03],\n",
       "          [-2.4050e-03, -1.8095e-03, -2.4188e-03,  ..., -3.2448e-04,\n",
       "            9.5902e-01, -5.4278e-03],\n",
       "          [-2.2607e-03,  3.3029e-03, -1.5608e-04,  ..., -2.0013e-03,\n",
       "           -2.1171e-03,  9.6285e-01]], device='cuda:0', requires_grad=True)),\n",
       " ('output.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-1.9846e-03, -7.1298e-03, -2.5126e-03, -1.0851e-03, -1.9573e-03,\n",
       "          -2.2839e-03, -1.6672e-03, -1.0686e-03, -2.9342e-03,  1.3588e-04,\n",
       "          -1.5644e-03, -2.2211e-03, -1.7274e-03, -3.2127e-03, -2.3969e-03,\n",
       "          -3.5492e-03, -1.1205e-03, -3.9791e-04, -1.4677e-03, -2.6073e-03,\n",
       "          -3.5227e-03, -3.2596e-03, -3.3519e-03, -2.1380e-04, -4.3601e-03,\n",
       "          -1.6947e-03, -2.4799e-03, -2.8686e-03, -1.7911e-03, -3.4687e-03,\n",
       "          -1.9409e-03, -1.9828e-03, -1.2867e-03, -9.7843e-05, -7.1348e-05,\n",
       "          -4.8096e-03, -1.5115e-04, -1.2159e-03, -3.9419e-03, -2.4520e-03,\n",
       "          -4.2670e-03, -3.8469e-03, -1.4745e-03, -3.4712e-03, -2.0891e-03,\n",
       "          -2.1477e-03, -1.3260e-03, -3.2074e-03, -1.5168e-03, -1.5016e-03,\n",
       "          -9.4485e-04, -4.1337e-03, -4.0911e-03, -1.5681e-03, -2.2593e-03,\n",
       "          -6.5873e-04, -2.1947e-03, -1.9598e-03,  1.8351e-06, -2.6437e-03,\n",
       "          -4.0293e-04, -3.1424e-03, -3.2843e-03, -2.1866e-03, -7.2564e-04,\n",
       "          -1.9332e-03,  1.7321e-04, -3.6399e-03, -4.9667e-04,  2.4558e-04,\n",
       "          -1.1080e-03, -1.0047e-03, -1.4612e-03, -2.6588e-03, -1.8057e-03,\n",
       "          -3.9741e-03, -7.4065e-04, -8.9082e-04, -1.9723e-03, -1.3308e-03,\n",
       "          -3.7372e-03, -3.0446e-03, -2.5299e-03, -5.5055e-04, -3.7434e-03,\n",
       "          -2.3128e-03, -2.4151e-03, -5.3012e-05, -1.6280e-03, -2.1030e-03,\n",
       "          -2.2543e-03, -2.0604e-03, -1.0325e-03, -4.6639e-05, -2.7638e-03,\n",
       "          -3.1865e-03, -2.2138e-03, -8.3445e-04, -2.3862e-03, -2.7130e-03,\n",
       "          -2.8049e-03, -2.4194e-03, -2.8043e-03, -5.0156e-04, -1.5140e-03,\n",
       "          -2.9392e-03, -1.1743e-03, -2.4619e-03, -1.3152e-03, -1.9326e-03,\n",
       "          -1.7629e-03, -1.6508e-03, -1.8103e-03, -1.8223e-03, -2.9875e-03,\n",
       "          -1.7081e-03, -2.3359e-03, -3.4196e-03, -3.5304e-03, -4.3471e-04,\n",
       "          -6.2879e-03, -1.7914e-03, -1.4432e-03, -9.7214e-04, -1.0289e-03,\n",
       "          -1.0618e-03, -2.0605e-03, -1.6886e-03, -1.6045e-03, -3.6263e-03,\n",
       "          -2.3806e-03, -1.2184e-03, -4.2203e-03, -1.7562e-04, -3.0472e-03,\n",
       "          -3.8669e-03, -1.2492e-03, -1.2316e-03, -1.7023e-03, -3.7931e-03,\n",
       "          -2.3935e-03, -3.2726e-03, -1.0818e-03, -7.6242e-04, -4.2148e-03,\n",
       "          -2.1893e-03, -6.5297e-04, -3.9133e-03, -3.2583e-03, -1.6535e-04,\n",
       "          -2.2654e-03, -3.5086e-03, -1.5326e-03, -9.8232e-04, -1.2851e-03,\n",
       "          -1.1088e-03, -1.5310e-03, -2.6882e-03, -1.3720e-03, -2.9167e-03,\n",
       "           4.7756e-04, -1.7723e-03, -2.6773e-03, -3.1839e-03, -2.6509e-03,\n",
       "          -4.5230e-04, -3.6386e-03, -2.7898e-03, -4.0396e-03, -2.8384e-03,\n",
       "          -1.1552e-03, -2.0277e-03, -2.6057e-03, -6.2250e-04, -2.3068e-03,\n",
       "          -4.2928e-03, -1.6307e-03, -3.4438e-03, -2.5574e-03, -2.4888e-03,\n",
       "          -3.0061e-03, -4.0309e-03, -1.2183e-03, -1.6875e-03, -1.8126e-03,\n",
       "          -2.2750e-03, -2.3166e-03, -1.5986e-03, -2.7740e-03, -3.1525e-03,\n",
       "          -2.6142e-03, -3.2138e-03, -2.5312e-03, -2.6012e-03, -1.2537e-03,\n",
       "          -1.2694e-03, -1.4745e-03, -2.3756e-03, -1.5259e-03, -2.3210e-04,\n",
       "          -2.1574e-03, -1.9319e-03, -7.6998e-04, -1.1943e-03, -2.7284e-03,\n",
       "          -1.9070e-03, -1.6461e-03, -2.1882e-03, -3.5662e-03, -2.5932e-03,\n",
       "          -6.9311e-04, -2.5444e-03, -3.2427e-03, -1.7902e-03, -6.2536e-04,\n",
       "          -2.4533e-03, -7.8107e-04, -1.4528e-03, -2.6541e-03, -3.8354e-03,\n",
       "          -3.5949e-03, -2.3734e-03, -3.3476e-03, -1.6295e-03, -2.3165e-03,\n",
       "          -2.2632e-03, -1.6618e-03, -1.1359e-03, -3.9323e-03, -1.6417e-03,\n",
       "          -5.0610e-04, -7.7664e-04, -1.5067e-03, -6.4533e-04, -2.5248e-03,\n",
       "          -2.3538e-03, -1.3585e-03,  1.7428e-04, -1.4014e-03, -4.9978e-03,\n",
       "          -7.8897e-04, -2.8368e-03, -1.1107e-03, -2.3214e-03, -2.0105e-03,\n",
       "          -1.2447e-03, -1.7349e-03,  2.3056e-04, -3.4305e-03, -1.0084e-03,\n",
       "          -3.6331e-03, -2.0983e-03, -1.9583e-03, -2.4628e-03, -1.8021e-03,\n",
       "          -8.8310e-04, -1.7920e-03, -1.2832e-03, -3.7297e-03, -2.1831e-03,\n",
       "          -2.0258e-03, -2.6853e-03, -7.1226e-04, -6.3174e-04, -2.3049e-03,\n",
       "          -2.0904e-03, -1.8745e-03, -3.3331e-03,  1.5628e-04, -4.6379e-04,\n",
       "          -9.6376e-04, -1.3144e-03, -1.6846e-03, -2.8678e-03, -2.7875e-04,\n",
       "          -2.2290e-04, -2.1986e-03, -2.2993e-03, -3.6246e-03, -3.4862e-04,\n",
       "          -5.7417e-04, -2.9465e-03, -2.3453e-03, -1.2542e-03, -3.2904e-03,\n",
       "          -2.1437e-03, -3.1695e-03, -3.8711e-03, -2.4133e-03, -4.2077e-03,\n",
       "          -3.5224e-03, -2.8116e-03, -1.1415e-03, -2.4674e-03, -7.8574e-04,\n",
       "          -3.0358e-03, -2.9028e-03,  8.2313e-04, -3.3485e-03, -2.8389e-03,\n",
       "          -3.6681e-03, -3.0470e-03, -3.0012e-03, -8.6583e-04, -2.4744e-03,\n",
       "          -2.5838e-03, -6.0042e-04, -2.7794e-03, -2.4882e-03, -2.8165e-03,\n",
       "          -3.1131e-03,  1.7076e-05, -9.4891e-04, -2.9903e-03, -6.2458e-04,\n",
       "          -5.9314e-04, -5.3086e-03, -2.1851e-03, -9.1761e-04, -3.2798e-03,\n",
       "          -2.0059e-03, -1.9060e-03, -2.0941e-03, -1.9551e-03, -1.7784e-03,\n",
       "          -1.3933e-03, -1.7407e-03, -2.6461e-03, -2.4138e-03, -2.4941e-03,\n",
       "          -4.6800e-04, -3.3999e-03, -3.6461e-03, -9.3444e-04, -3.5408e-03,\n",
       "          -1.5802e-03, -2.8258e-03, -3.9511e-03, -2.0482e-03, -2.0992e-03,\n",
       "          -1.0880e-03, -1.3183e-03, -2.4016e-03, -2.6994e-03, -3.6987e-03,\n",
       "          -4.5450e-03, -2.8794e-03, -1.7242e-03, -2.8952e-03, -2.1904e-03,\n",
       "          -3.7818e-03, -9.5981e-04, -1.3784e-03, -2.7415e-03, -1.4553e-03,\n",
       "          -3.0963e-03, -1.6009e-03, -1.1628e-03,  2.4487e-04, -9.6195e-04,\n",
       "          -1.3919e-03, -1.7043e-03,  1.5832e-04, -1.5174e-03, -1.5450e-03,\n",
       "          -8.7819e-04, -3.5556e-04, -2.1098e-03, -1.9203e-03, -2.5131e-03,\n",
       "          -1.9782e-03,  5.9893e-05, -4.6687e-03, -1.1029e-04, -9.8268e-04,\n",
       "          -9.0279e-04, -3.3756e-03, -3.9636e-03, -5.0465e-03, -2.5283e-03,\n",
       "          -1.4938e-03, -3.1945e-03, -2.0639e-04, -2.7926e-03, -3.5329e-03,\n",
       "          -7.3617e-04, -2.5758e-03, -2.3934e-03, -3.7604e-04, -8.2610e-04,\n",
       "          -1.1390e-03, -3.4616e-03, -3.7545e-03, -1.7316e-03,  9.5687e-04,\n",
       "          -2.2346e-03, -1.8529e-03, -3.2064e-03, -2.1810e-03, -2.8921e-05,\n",
       "          -8.7425e-04, -3.0046e-03, -2.7840e-03, -3.1236e-03, -1.2691e-03,\n",
       "          -3.3666e-03, -2.4901e-03, -2.5302e-03, -3.1922e-03, -3.9604e-03,\n",
       "          -1.4886e-03, -9.1193e-04, -3.3624e-03, -2.7411e-03, -1.3519e-03,\n",
       "          -2.1783e-03, -2.8821e-03, -3.6813e-03, -3.0642e-03, -3.9476e-03,\n",
       "          -2.6682e-03, -5.1396e-04, -2.4065e-03, -3.1088e-03, -2.5482e-03,\n",
       "          -2.5356e-03, -2.4773e-03, -2.0266e-03, -1.3873e-04, -2.3293e-03,\n",
       "          -2.1998e-03, -2.0672e-03, -2.6448e-03, -1.5653e-03, -1.6351e-03,\n",
       "          -2.1030e-03, -1.7968e-03, -1.6776e-03, -2.5334e-03, -1.1587e-03,\n",
       "          -2.6731e-03,  8.8192e-05, -3.5965e-04, -1.0377e-03, -5.4277e-04,\n",
       "          -3.6573e-03, -1.1613e-03, -3.4296e-03, -4.0332e-03, -2.2459e-03,\n",
       "          -1.9902e-03, -3.3289e-03, -4.1866e-03, -1.6724e-05, -2.2019e-03,\n",
       "          -3.3088e-03, -2.5963e-03, -1.0425e-03, -1.7253e-03, -2.3281e-03,\n",
       "           1.1521e-04,  3.2314e-03, -1.2977e-03, -1.7152e-03, -2.0392e-03,\n",
       "          -4.8865e-03, -1.8953e-03, -2.2472e-03, -1.6633e-03, -3.5961e-03,\n",
       "          -2.4914e-03, -2.7008e-03, -3.2686e-03, -6.7299e-04, -1.3465e-03,\n",
       "          -4.0711e-03, -1.0471e-03, -6.0011e-03, -1.3569e-03, -5.0752e-04,\n",
       "          -3.6002e-03, -2.0796e-03, -2.2300e-03, -1.2297e-03, -9.1577e-04,\n",
       "          -2.9246e-03, -5.7756e-05, -2.3219e-03, -8.0895e-04, -3.7455e-03,\n",
       "          -1.9770e-03, -3.7077e-03, -2.7896e-03, -3.4794e-03, -3.1297e-03,\n",
       "          -1.7922e-03, -4.0725e-03, -1.1262e-03, -1.9461e-03, -1.3795e-03,\n",
       "          -1.4302e-03, -1.6886e-03, -4.7288e-04, -1.2494e-03, -1.7888e-03,\n",
       "          -1.7143e-03, -2.1246e-03, -1.3164e-03, -1.6181e-03, -3.4488e-03,\n",
       "           5.8277e-05, -2.3932e-03, -2.2130e-03, -6.2642e-03,  8.8113e-05,\n",
       "          -1.0344e-03, -3.5671e-03, -3.0009e-03, -6.5001e-04, -1.7569e-03,\n",
       "          -9.8495e-04, -1.0701e-03, -9.2737e-04, -1.1289e-03, -5.9224e-04,\n",
       "          -1.5701e-03, -3.4997e-03, -2.6268e-03, -2.9639e-03, -1.3838e-03,\n",
       "          -4.0090e-03, -1.3565e-03, -4.5359e-03, -3.1745e-03, -3.3115e-03,\n",
       "          -5.0865e-04, -2.1802e-03, -3.6621e-03, -2.4303e-03, -2.1194e-03,\n",
       "          -2.1625e-03, -1.0959e-03, -6.7307e-04, -7.0932e-04, -4.6968e-04,\n",
       "          -3.4895e-03, -3.7183e-03, -3.0259e-03,  1.3950e-04, -2.1604e-03,\n",
       "          -1.4113e-03, -3.0392e-03, -3.3275e-03, -2.1014e-03, -9.6676e-04,\n",
       "          -5.6900e-03, -2.7647e-03, -3.4078e-03, -6.5009e-06, -2.9587e-03,\n",
       "          -2.1540e-03, -4.1028e-03, -1.5468e-03, -4.0350e-04, -1.6409e-03,\n",
       "          -1.4624e-03, -4.4131e-03, -1.9524e-03,  5.9417e-04, -4.9488e-04,\n",
       "          -2.7613e-03, -3.2655e-03, -2.5436e-03, -9.0606e-04, -8.5801e-04,\n",
       "          -3.2403e-03, -2.6382e-03, -9.7226e-04, -1.1679e-03, -2.8428e-03,\n",
       "          -9.7589e-04, -3.3282e-03, -1.7310e-03, -2.0126e-03, -1.0777e-04,\n",
       "          -2.1395e-03, -1.6139e-03, -1.5099e-03, -2.1135e-03, -4.1501e-03,\n",
       "           1.7235e-04, -1.4784e-03, -2.7388e-03, -1.3152e-03, -3.0420e-04,\n",
       "          -1.2141e-03, -3.5898e-03, -2.8596e-03, -2.2308e-04, -2.2134e-03,\n",
       "          -1.5563e-03, -1.3982e-03, -8.8299e-04, -1.0175e-03,  2.1858e-04,\n",
       "          -2.2071e-03, -1.9684e-03, -2.6575e-03,  7.5293e-04, -2.6886e-03,\n",
       "          -3.8256e-03, -2.6037e-03, -2.7599e-03, -1.3192e-03, -3.4363e-03,\n",
       "          -1.0953e-03, -3.9324e-04, -1.0507e-03, -1.0831e-03, -6.3144e-04,\n",
       "          -2.0519e-03, -6.6785e-04, -4.0434e-03, -1.5900e-03, -1.7008e-03,\n",
       "          -1.0693e-03, -1.0111e-03, -1.9222e-04, -2.4672e-03, -2.2236e-03,\n",
       "          -1.4745e-04, -2.5477e-03, -2.1645e-03, -1.3540e-03, -1.6538e-03,\n",
       "          -2.8825e-03, -4.0080e-03, -2.7130e-03, -1.7860e-03, -1.0806e-03,\n",
       "          -9.4404e-04, -4.0711e-03, -2.1894e-03, -3.2490e-03, -3.7721e-03,\n",
       "          -3.1803e-04, -3.3033e-03, -1.7010e-03,  2.7584e-05, -1.5218e-03,\n",
       "          -1.3552e-03, -3.0094e-03,  9.3669e-05, -5.7738e-04, -2.6715e-03,\n",
       "          -2.5784e-03, -1.6972e-03, -5.1022e-04, -1.4399e-03, -5.8644e-04,\n",
       "          -7.9761e-04, -6.8383e-04, -3.2070e-03, -5.8934e-04, -3.0699e-03,\n",
       "          -2.4940e-03, -3.5946e-04, -1.9030e-03,  3.4001e-05, -1.3527e-03,\n",
       "          -1.3797e-03, -1.1911e-03, -2.9258e-03, -1.8252e-03, -2.3545e-03,\n",
       "          -7.2363e-04, -3.6712e-03, -7.0863e-04, -2.3223e-03, -2.0759e-03,\n",
       "          -2.8487e-03, -1.2134e-03, -3.9259e-03, -2.4649e-03, -1.8475e-03,\n",
       "          -2.7936e-03, -1.0190e-03, -2.2007e-03, -1.2405e-03, -1.5094e-03,\n",
       "          -1.0235e-03,  1.3771e-04, -8.9569e-04, -2.5483e-03, -5.2794e-03,\n",
       "          -2.1651e-03, -5.6750e-04, -2.6777e-03, -2.7554e-03, -9.8954e-04,\n",
       "          -2.8404e-03, -3.1528e-03, -1.1965e-03, -8.7689e-04, -3.3591e-03,\n",
       "          -2.8115e-03, -4.5211e-04, -1.2289e-03, -1.7138e-03, -3.7974e-04,\n",
       "          -1.6726e-03, -2.0358e-03, -1.5985e-03, -1.3504e-03, -2.8453e-03,\n",
       "          -5.5652e-04, -2.4477e-03, -2.3742e-03, -1.3560e-03, -3.9093e-04,\n",
       "          -7.7444e-04, -2.0944e-03, -7.5597e-04, -1.8432e-03, -1.7210e-03,\n",
       "          -3.7822e-04, -1.7574e-03, -2.5747e-03, -1.4701e-03, -2.6700e-03,\n",
       "          -3.0981e-03, -1.8637e-03, -2.4990e-03, -1.5376e-03, -2.3324e-03,\n",
       "          -2.4731e-03, -3.2889e-03, -4.6813e-03, -3.1365e-03, -3.4794e-03,\n",
       "          -8.9739e-04, -1.5115e-03, -2.6140e-03, -3.0647e-04, -2.2402e-03,\n",
       "          -4.1911e-03, -1.3490e-03, -1.6010e-04, -1.4725e-03, -2.8700e-03,\n",
       "          -2.9896e-03, -4.9832e-04, -2.1222e-03, -6.4326e-04, -4.3776e-03,\n",
       "          -5.5320e-03,  1.4749e-03, -2.1239e-03, -2.1681e-03, -1.4635e-03,\n",
       "          -2.1902e-03, -2.0312e-03, -2.6587e-03, -2.0554e-03, -2.1894e-03,\n",
       "          -1.9970e-03, -3.0672e-03, -3.3580e-03], device='cuda:0',\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db0f6cbdde3eb805f0a229b988d6bd72d452c42e640dd9958b4355934ec01bf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
